{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essay_id          12976\n",
       "essay_set         12976\n",
       "essay             12976\n",
       "rater1_domain1    12976\n",
       "rater2_domain1    12976\n",
       "rater3_domain1      128\n",
       "domain1_score     12976\n",
       "rater1_domain2     1800\n",
       "rater2_domain2     1800\n",
       "domain2_score      1800\n",
       "rater1_trait1      2292\n",
       "rater1_trait2      2292\n",
       "rater1_trait3      2292\n",
       "rater1_trait4      2292\n",
       "rater1_trait5       723\n",
       "rater1_trait6       723\n",
       "rater2_trait1      2292\n",
       "rater2_trait2      2292\n",
       "rater2_trait3      2292\n",
       "rater2_trait4      2292\n",
       "rater2_trait5       723\n",
       "rater2_trait6       723\n",
       "rater3_trait1       128\n",
       "rater3_trait2       128\n",
       "rater3_trait3       128\n",
       "rater3_trait4       128\n",
       "rater3_trait5       128\n",
       "rater3_trait6       128\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./asap-aes/training_set_rel3.tsv', sep='\\t', encoding = \"latin\")\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "3             NaN             NaN            NaN  ...            NaN   \n",
       "4             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "essay_id          12701\n",
       "essay_set         12701\n",
       "essay             12701\n",
       "rater1_domain1    12701\n",
       "rater2_domain1    12701\n",
       "rater3_domain1      128\n",
       "domain1_score     12701\n",
       "rater1_domain2     1799\n",
       "rater2_domain2     1799\n",
       "domain2_score      1799\n",
       "rater1_trait1      2055\n",
       "rater1_trait2      2055\n",
       "rater1_trait3      2055\n",
       "rater1_trait4      2055\n",
       "rater1_trait5       722\n",
       "rater1_trait6       722\n",
       "rater2_trait1      2055\n",
       "rater2_trait2      2055\n",
       "rater2_trait3      2055\n",
       "rater2_trait4      2055\n",
       "rater2_trait5       722\n",
       "rater2_trait6       722\n",
       "rater3_trait1       128\n",
       "rater3_trait2       128\n",
       "rater3_trait3       128\n",
       "rater3_trait4       128\n",
       "rater3_trait5       128\n",
       "rater3_trait6       128\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['illegible']=data.essay.str.contains('(\\?\\?\\?|illegible|not legible)')\n",
    "#data.groupby(['essay_set','illegible']).count()\n",
    "#data[data.illegible==True].count()\n",
    "data = data[data.illegible==False]\n",
    "data = data.drop('illegible', 1)\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>rater1_trait1</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12701.000000</td>\n",
       "      <td>12701.000000</td>\n",
       "      <td>12701.000000</td>\n",
       "      <td>12701.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>12701.000000</td>\n",
       "      <td>1799.000000</td>\n",
       "      <td>1799.000000</td>\n",
       "      <td>1799.000000</td>\n",
       "      <td>2055.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2055.000000</td>\n",
       "      <td>2055.000000</td>\n",
       "      <td>722.000000</td>\n",
       "      <td>722.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10146.245020</td>\n",
       "      <td>4.129832</td>\n",
       "      <td>4.057791</td>\n",
       "      <td>4.068341</td>\n",
       "      <td>37.828125</td>\n",
       "      <td>6.635226</td>\n",
       "      <td>3.334074</td>\n",
       "      <td>3.330739</td>\n",
       "      <td>3.334074</td>\n",
       "      <td>2.504136</td>\n",
       "      <td>...</td>\n",
       "      <td>2.708029</td>\n",
       "      <td>2.773723</td>\n",
       "      <td>3.778393</td>\n",
       "      <td>3.590028</td>\n",
       "      <td>3.945312</td>\n",
       "      <td>3.890625</td>\n",
       "      <td>4.078125</td>\n",
       "      <td>3.992188</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>3.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6266.038381</td>\n",
       "      <td>2.123600</td>\n",
       "      <td>4.205748</td>\n",
       "      <td>4.259040</td>\n",
       "      <td>5.240829</td>\n",
       "      <td>8.945280</td>\n",
       "      <td>0.729263</td>\n",
       "      <td>0.726967</td>\n",
       "      <td>0.729263</td>\n",
       "      <td>1.229647</td>\n",
       "      <td>...</td>\n",
       "      <td>1.168146</td>\n",
       "      <td>1.061814</td>\n",
       "      <td>0.689271</td>\n",
       "      <td>0.693389</td>\n",
       "      <td>0.643668</td>\n",
       "      <td>0.630390</td>\n",
       "      <td>0.622535</td>\n",
       "      <td>0.509687</td>\n",
       "      <td>0.538845</td>\n",
       "      <td>0.603417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4372.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9941.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15513.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21633.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           essay_id     essay_set  rater1_domain1  rater2_domain1  \\\n",
       "count  12701.000000  12701.000000    12701.000000    12701.000000   \n",
       "mean   10146.245020      4.129832        4.057791        4.068341   \n",
       "std     6266.038381      2.123600        4.205748        4.259040   \n",
       "min        1.000000      1.000000        0.000000        0.000000   \n",
       "25%     4372.000000      2.000000        2.000000        2.000000   \n",
       "50%     9941.000000      4.000000        3.000000        3.000000   \n",
       "75%    15513.000000      6.000000        4.000000        4.000000   \n",
       "max    21633.000000      8.000000       30.000000       30.000000   \n",
       "\n",
       "       rater3_domain1  domain1_score  rater1_domain2  rater2_domain2  \\\n",
       "count      128.000000   12701.000000     1799.000000     1799.000000   \n",
       "mean        37.828125       6.635226        3.334074        3.330739   \n",
       "std          5.240829       8.945280        0.729263        0.726967   \n",
       "min         20.000000       0.000000        1.000000        1.000000   \n",
       "25%         36.000000       2.000000        3.000000        3.000000   \n",
       "50%         40.000000       3.000000        3.000000        3.000000   \n",
       "75%         40.000000       8.000000        4.000000        4.000000   \n",
       "max         50.000000      60.000000        4.000000        4.000000   \n",
       "\n",
       "       domain2_score  rater1_trait1  ...  rater2_trait3  rater2_trait4  \\\n",
       "count    1799.000000    2055.000000  ...    2055.000000    2055.000000   \n",
       "mean        3.334074       2.504136  ...       2.708029       2.773723   \n",
       "std         0.729263       1.229647  ...       1.168146       1.061814   \n",
       "min         1.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         3.000000       2.000000  ...       2.000000       2.000000   \n",
       "50%         3.000000       2.000000  ...       2.000000       3.000000   \n",
       "75%         4.000000       3.000000  ...       4.000000       4.000000   \n",
       "max         4.000000       6.000000  ...       6.000000       6.000000   \n",
       "\n",
       "       rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "count     722.000000     722.000000     128.000000     128.000000   \n",
       "mean        3.778393       3.590028       3.945312       3.890625   \n",
       "std         0.689271       0.693389       0.643668       0.630390   \n",
       "min         1.000000       1.000000       2.000000       2.000000   \n",
       "25%         3.000000       3.000000       4.000000       4.000000   \n",
       "50%         4.000000       4.000000       4.000000       4.000000   \n",
       "75%         4.000000       4.000000       4.000000       4.000000   \n",
       "max         6.000000       6.000000       6.000000       6.000000   \n",
       "\n",
       "       rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "count     128.000000     128.000000     128.000000     128.000000  \n",
       "mean        4.078125       3.992188       3.843750       3.617188  \n",
       "std         0.622535       0.509687       0.538845       0.603417  \n",
       "min         2.000000       3.000000       2.000000       2.000000  \n",
       "25%         4.000000       4.000000       4.000000       3.000000  \n",
       "50%         4.000000       4.000000       4.000000       4.000000  \n",
       "75%         4.000000       4.000000       4.000000       4.000000  \n",
       "max         6.000000       6.000000       5.000000       5.000000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data.essay)\n",
    "np.save('./wow/lol', x, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in tqdm(f):\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "733it [00:00, 7325.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400001it [00:44, 8962.48it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. 400001  words loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "glove = loadGloveModel('glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences, verbose =  True):\n",
    "    vocab = {}\n",
    "    for sentence in tqdm(sentences, disable = (not verbose)):\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator \n",
    "\n",
    "def check_coverage(vocab,embeddings_index):\n",
    "    a = {}\n",
    "    oov = {}\n",
    "    k = 0\n",
    "    i = 0\n",
    "    for word in tqdm(vocab):\n",
    "        try:\n",
    "            a[word] = embeddings_index[word]\n",
    "            k += vocab[word]\n",
    "        except:\n",
    "\n",
    "            oov[word] = vocab[word]\n",
    "            i += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
    "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(essay, replaceCommon, removeSW=False):\n",
    "    if removeSW:\n",
    "        for punct in \"/-'\":\n",
    "            essay = essay.replace(punct, ' ')\n",
    "        for punct in '&':\n",
    "            essay = essay.replace(punct, f' {punct} ')\n",
    "        for punct in '?!.,\"#$%\\'()*+-/:;<=>[\\\\]^_`{|}~' + '“”’':\n",
    "            essay = essay.replace(punct, '')\n",
    "    essay = essay.lower()\n",
    "    essay = re.sub(\"\\x92\",\"'\",essay)\n",
    "    essay = re.sub(\"\\x96\",\"-\",essay)\n",
    "    essay = re.sub(\"\\x93\",'\"',essay)\n",
    "    essay = re.sub(\"\\x94\",'\"',essay)\n",
    "    essay = re.sub(\"n't\",\" not\",essay)\n",
    "    essay = re.sub(\"'re\",\" are\",essay)\n",
    "    essay = re.sub(\"it's\",\"it is\",essay)\n",
    "    essay = re.sub(\"'ve'\",\" have\",essay)\n",
    "    for punct in ',.&?)!\"(:\\'':\n",
    "        essay = essay.replace(punct, f' {punct} ')\n",
    "    #replace ner to common example\n",
    "    if replaceCommon:\n",
    "        essay = re.sub(\"@person[^ ]*\",\"john\",essay)\n",
    "        essay = re.sub(\"@month[^ ]*\",\"january\",essay)\n",
    "        essay = re.sub(\"@location[^ ]*\",\"italy\",essay)\n",
    "        essay = re.sub(\"@num[^ ]*\",\"1\",essay)\n",
    "        essay = re.sub(\"@organization[^ ]*\",\"google\",essay)\n",
    "        essay = re.sub(\"@date[^ ]*\",\"3rd may\",essay)\n",
    "        essay = re.sub(\"@percent[^ ]*\",\"100 %\",essay)\n",
    "        essay = re.sub(\"@money[^ ]*\",\"$ 1\",essay)\n",
    "        essay = re.sub(\"@time[^ ]*\",\"1am\",essay)\n",
    "        essay = re.sub(\"@dr[^ ]*\",\"dr john\",essay)\n",
    "        essay = re.sub(\"@caps[^ ]*\",\"peter\",essay)\n",
    "    return essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeEssayArr(replaceCommon, removeSW):\n",
    "    sentences = []\n",
    "    for essay in data.essay:\n",
    "        essay = clean(essay,replaceCommon=replaceCommon, removeSW=removeSW)\n",
    "        sentences.append(essay.split())\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12701/12701 [00:00<00:00, 14167.69it/s]\n",
      "100%|██████████| 39911/39911 [00:00<00:00, 598650.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 53.51% of vocab\n",
      "Found embeddings for  98.90% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('greatful', 281),\n",
       " ('kurmaskie', 267),\n",
       " ('lüsted', 263),\n",
       " ('shelfs', 188),\n",
       " ('shouldnt', 151),\n",
       " ('thousand-foot', 142),\n",
       " ('benifit', 134),\n",
       " ('diffrent', 133),\n",
       " ('minfong', 130),\n",
       " ('flamable', 124),\n",
       " ('libary', 114),\n",
       " ('auther', 109),\n",
       " ('cordination', 107),\n",
       " ('somthing', 105),\n",
       " ('librarys', 102),\n",
       " ('obsticles', 100),\n",
       " ('inapropriate', 83),\n",
       " ('innapropriate', 83),\n",
       " ('offened', 76),\n",
       " ('childern', 75),\n",
       " ('obsticle', 73),\n",
       " ('familys', 65),\n",
       " ('freinds', 62),\n",
       " ('differnt', 61),\n",
       " ('¶', 59),\n",
       " ('certian', 55),\n",
       " ('exersize', 52),\n",
       " ('comunicate', 52),\n",
       " ('useing', 52),\n",
       " ('librarie', 51),\n",
       " ('reson', 51),\n",
       " ('magizines', 49),\n",
       " ('computors', 49),\n",
       " ('excersise', 48),\n",
       " ('inappropiate', 47),\n",
       " ('benifits', 47),\n",
       " ('â\\x80\\x9d', 46),\n",
       " ('childeren', 46),\n",
       " ('chating', 46),\n",
       " ('everyones', 46),\n",
       " ('memior', 45),\n",
       " ('offencive', 44),\n",
       " ('completly', 44),\n",
       " ('excersize', 44),\n",
       " ('exersise', 44),\n",
       " ('greatfulness', 43),\n",
       " ('buisnesses', 43),\n",
       " ('gratefull', 41),\n",
       " ('appropiate', 41),\n",
       " ('insted', 41),\n",
       " ('libaries', 40),\n",
       " ('definetly', 40),\n",
       " ('oppinion', 40),\n",
       " ('chrome-nickel', 39),\n",
       " ('possitive', 39),\n",
       " ('drigibles', 37),\n",
       " ('haveing', 37),\n",
       " ('offinsive', 35),\n",
       " ('innappropriate', 35),\n",
       " ('â\\x80\\x9cpeter', 34),\n",
       " ('sacrafice', 34),\n",
       " ('certin', 34),\n",
       " ('computor', 34),\n",
       " ('negitive', 34),\n",
       " ('usefull', 34),\n",
       " ('greatfull', 33),\n",
       " ('becaus', 33),\n",
       " ('wheather', 33),\n",
       " ('cencorship', 32),\n",
       " ('magizine', 32),\n",
       " ('intrest', 32),\n",
       " ('writting', 32),\n",
       " ('werent', 31),\n",
       " ('\\x91', 30),\n",
       " ('tryed', 30),\n",
       " ('helpfull', 30),\n",
       " ('libray', 29),\n",
       " ('relized', 29),\n",
       " ('personaly', 28),\n",
       " ('pacient', 27),\n",
       " ('thankfull', 27),\n",
       " ('makeing', 27),\n",
       " ('relize', 27),\n",
       " ('excersising', 27),\n",
       " ('allways', 27),\n",
       " ('resons', 27),\n",
       " ('peice', 26),\n",
       " ('definatly', 26),\n",
       " ('gratefullness', 25),\n",
       " ('probly', 25),\n",
       " ('excercising', 25),\n",
       " ('unpatient', 24),\n",
       " ('derigibles', 24),\n",
       " ('enviornment', 24),\n",
       " ('veiw', 24),\n",
       " ('dosent', 24),\n",
       " ('wating', 24),\n",
       " ('selfs', 24),\n",
       " ('obsticals', 23),\n",
       " ('thoes', 23),\n",
       " ('imformation', 23),\n",
       " ('posotive', 23),\n",
       " ('comunication', 23),\n",
       " ('opion', 23),\n",
       " ('finnaly', 23),\n",
       " ('themselfs', 23),\n",
       " ('cencored', 22),\n",
       " ('tooken', 22),\n",
       " ('abhor-', 22),\n",
       " ('enviorment', 22),\n",
       " ('it;', 22),\n",
       " ('socity', 22),\n",
       " ('enternet', 22),\n",
       " ('bestfriend', 22),\n",
       " ('basicly', 22),\n",
       " ('immagrants', 21),\n",
       " ('veiws', 21),\n",
       " ('easyer', 21),\n",
       " ('activitys', 21),\n",
       " ('exersice', 21),\n",
       " ('conclution', 21),\n",
       " ('tarlike', 20),\n",
       " ('creats', 20),\n",
       " ('takeing', 20),\n",
       " ('becase', 20),\n",
       " ('beggining', 20),\n",
       " ('exersizing', 20),\n",
       " ('buissness', 20),\n",
       " ('drigible', 19),\n",
       " ('parants', 19),\n",
       " ('becouse', 19),\n",
       " ('shoping', 19),\n",
       " ('rember', 19),\n",
       " ('beacause', 19),\n",
       " ('controll', 19),\n",
       " ('authour', 18),\n",
       " ('abhor-then', 18),\n",
       " ('shevles', 18),\n",
       " ('shelf-', 18),\n",
       " ('whent', 18),\n",
       " ('dieing', 18),\n",
       " ('comptuer', 18),\n",
       " ('exercis', 18),\n",
       " ('probaly', 18),\n",
       " ('likly', 18),\n",
       " ('dirigables', 17),\n",
       " ('imigrants', 17),\n",
       " ('exerpt', 17),\n",
       " ('shelf-that', 17),\n",
       " ('writen', 17),\n",
       " ('absolutly', 17),\n",
       " ('agian', 17),\n",
       " ('typeing', 17),\n",
       " ('exercize', 17),\n",
       " ('remeber', 17),\n",
       " ('knoledge', 17),\n",
       " ('alow', 17),\n",
       " ('labtop', 17),\n",
       " ('didn`t', 16),\n",
       " ('censore', 16),\n",
       " ('censorships', 16),\n",
       " ('cenorship', 16),\n",
       " ('magzines', 16),\n",
       " ('catagories', 16),\n",
       " ('affensive', 16),\n",
       " ('inapropiate', 16),\n",
       " ('whant', 16),\n",
       " ('anothe', 16),\n",
       " ('intresting', 16),\n",
       " ('comming', 16),\n",
       " ('comuter', 16),\n",
       " ('awsome', 16),\n",
       " ('benificial', 16),\n",
       " ('wated', 15),\n",
       " ('happieness', 15),\n",
       " ('rawedia', 15),\n",
       " ('careing', 15),\n",
       " ('water-depleting', 15),\n",
       " ('me;', 15),\n",
       " ('moive', 15),\n",
       " ('oppinions', 15),\n",
       " ('rediculous', 15),\n",
       " ('alittle', 15),\n",
       " ('libraies', 15),\n",
       " ('apropriate', 15),\n",
       " ('coordiantion', 15),\n",
       " ('probally', 15),\n",
       " ('excersizing', 15),\n",
       " ('avalible', 15),\n",
       " ('vaction', 15),\n",
       " ('oppertunity', 15),\n",
       " ('oovoo', 15),\n",
       " ('studing', 15),\n",
       " ('peolpe', 15),\n",
       " ('dirigble', 14),\n",
       " ('flamible', 14),\n",
       " ('pharagraph', 14),\n",
       " ('cycleist', 14),\n",
       " ('liturature', 14),\n",
       " ('disapointed', 14),\n",
       " ('offesive', 14),\n",
       " ('libraires', 14),\n",
       " ('beging', 14),\n",
       " ('speach', 14),\n",
       " ('peopel', 14),\n",
       " ('<100', 14),\n",
       " ('internent', 14),\n",
       " ('adicted', 14),\n",
       " ('flameable', 13),\n",
       " ('obstical', 13),\n",
       " ('building;', 13),\n",
       " ('grabed', 13),\n",
       " ('oppion', 13),\n",
       " ('decied', 13),\n",
       " ('alowed', 13),\n",
       " ('excersing', 13),\n",
       " ('everone', 13),\n",
       " ('beable', 13),\n",
       " ('extreamly', 13),\n",
       " ('obeast', 13),\n",
       " ('now-a-days', 13),\n",
       " ('wouldent', 13),\n",
       " ('couldent', 13),\n",
       " ('cordanation', 13),\n",
       " ('benefitial', 13),\n",
       " ('friends/family', 13),\n",
       " ('unfortunatly', 13),\n",
       " ('a+', 13),\n",
       " ('dirigbles', 12),\n",
       " ('loveing', 12),\n",
       " ('discribes', 12),\n",
       " ('cyclsit', 12),\n",
       " ('discribed', 12),\n",
       " ('life;', 12),\n",
       " ('offeneded', 12),\n",
       " ('censory', 12),\n",
       " ('apon', 12),\n",
       " ('moives', 12),\n",
       " ('libaray', 12),\n",
       " ('violance', 12),\n",
       " ('neiborhood', 12),\n",
       " ('intellegent', 12),\n",
       " ('whould', 12),\n",
       " ('oppions', 12),\n",
       " ('somtimes', 12),\n",
       " ('oppurtunity', 12),\n",
       " ('shuld', 12),\n",
       " ('world;', 12),\n",
       " ('excrise', 12),\n",
       " ('knowlage', 12),\n",
       " ('convient', 12),\n",
       " ('shold', 12),\n",
       " ('maby', 12),\n",
       " ('comuters', 12),\n",
       " ('vidio', 12),\n",
       " ('reaserch', 12),\n",
       " ('pacience', 11),\n",
       " ('dirigable', 11),\n",
       " ('obsticales', 11),\n",
       " ('[his]', 11),\n",
       " ('cyclest', 11),\n",
       " ('intitled', 11),\n",
       " ('offensive;', 11),\n",
       " ('beleave', 11),\n",
       " ('relizes', 11),\n",
       " ('diffent', 11),\n",
       " ('ammount', 11),\n",
       " ('people;', 11),\n",
       " ('actualy', 11),\n",
       " ('habbits', 11),\n",
       " ('probley', 11),\n",
       " ('usally', 11),\n",
       " ('anywere', 11),\n",
       " ('@state1', 11),\n",
       " ('theese', 11),\n",
       " ('alows', 11),\n",
       " ('familly', 11),\n",
       " ('x-box', 11),\n",
       " ('inconclusion', 11),\n",
       " ('example;', 11),\n",
       " ('thoughs', 11),\n",
       " ('benifiting', 11),\n",
       " ('arguements', 11),\n",
       " ('frends', 11),\n",
       " ('artical', 11),\n",
       " ('obease', 11),\n",
       " ('things;', 11),\n",
       " ('patiences', 10),\n",
       " ('greatfullness', 10),\n",
       " ('gratful', 10),\n",
       " ('thankfullness', 10),\n",
       " ('memorys', 10),\n",
       " ('desserted', 10),\n",
       " ('ahead;', 10),\n",
       " ('it`s', 10),\n",
       " ('romoved', 10),\n",
       " ('abhor--then', 10),\n",
       " ('eveyone', 10),\n",
       " ('sensored', 10),\n",
       " ('computar', 10),\n",
       " ('library;', 10),\n",
       " ('suppost', 10),\n",
       " ('waching', 10),\n",
       " ('way;', 10),\n",
       " ('<1', 10),\n",
       " ('experince', 10),\n",
       " ('anyones', 10),\n",
       " ('succed', 10),\n",
       " ('supose', 10),\n",
       " ('convinient', 10),\n",
       " ('innapropiate', 10),\n",
       " ('beleve', 10),\n",
       " ('pritty', 10),\n",
       " ('opend', 10),\n",
       " ('is;', 10),\n",
       " ('her;', 10),\n",
       " ('benfit', 10),\n",
       " ('unappropriate', 10),\n",
       " ('diferent', 10),\n",
       " ('inportant', 10),\n",
       " ('w/', 10),\n",
       " ('frinds', 10),\n",
       " ('wernt', 10),\n",
       " ('exsample', 10),\n",
       " ('dident', 10),\n",
       " ('videochat', 10),\n",
       " ('compters', 10),\n",
       " ('easly', 10),\n",
       " ('handeye', 10),\n",
       " ('soceity', 10),\n",
       " ('adays', 10),\n",
       " ('laughter;', 9),\n",
       " ('obstacals', 9),\n",
       " ('dirgibles', 9),\n",
       " ('densly', 9),\n",
       " ('ontop', 9),\n",
       " ('derigible', 9),\n",
       " ('went-and', 9),\n",
       " ('blond-brick', 9),\n",
       " ('hapiness', 9),\n",
       " ('vowe', 9),\n",
       " ('don`t', 9),\n",
       " ('riadin', 9),\n",
       " ('lilbrary', 9),\n",
       " ('liberary', 9),\n",
       " ('unexceptable', 9),\n",
       " ('labraries', 9),\n",
       " ('niether', 9),\n",
       " ('sombody', 9),\n",
       " ('non-offensive', 9),\n",
       " ('alchol', 9),\n",
       " ('inappropraite', 9),\n",
       " ('vulger', 9),\n",
       " ('deside', 9),\n",
       " ('shouldent', 9),\n",
       " ('comeing', 9),\n",
       " ('awile', 9),\n",
       " ('sincerly', 9),\n",
       " ('litature', 9),\n",
       " ('compiuters', 9),\n",
       " ('peices', 9),\n",
       " ('accessable', 9),\n",
       " ('learing', 9),\n",
       " ('relitives', 9),\n",
       " ('expierence', 9),\n",
       " ('perfer', 9),\n",
       " ('lieing', 9),\n",
       " ('truble', 9),\n",
       " ('obeasity', 9),\n",
       " ('belifs', 9),\n",
       " ('arive', 9),\n",
       " ('#1', 9),\n",
       " ('commputer', 9),\n",
       " ('whay', 9),\n",
       " ('pepole', 9),\n",
       " ('voilence', 9),\n",
       " ('tuch', 9),\n",
       " ('wasent', 9),\n",
       " ('vertual', 9),\n",
       " ('faimly', 9),\n",
       " ('posative', 9),\n",
       " ('socialy', 9),\n",
       " ('usualy', 9),\n",
       " ('exersising', 9),\n",
       " ('weither', 9),\n",
       " ('concideration', 9),\n",
       " ('benifical', 9),\n",
       " ('excersice', 9),\n",
       " ('cheak', 9),\n",
       " ('excerise', 9),\n",
       " ('beileve', 9),\n",
       " ('habbit', 9),\n",
       " ('troble', 9),\n",
       " ('gt;', 8),\n",
       " ('pation', 8),\n",
       " ('paitent', 8),\n",
       " ('stepped-back', 8),\n",
       " ('clavan', 8),\n",
       " ('diribles', 8),\n",
       " ('hellium', 8),\n",
       " ('happines', 8),\n",
       " ('¶1', 8),\n",
       " ('joyfull', 8),\n",
       " ('graditude', 8),\n",
       " ('laught', 8),\n",
       " ('dehidrated', 8),\n",
       " ('patien', 8),\n",
       " ('libarie', 8),\n",
       " ('becaues', 8),\n",
       " ('i-pod', 8),\n",
       " ('shelvs', 8),\n",
       " ('exspecially', 8),\n",
       " ('books;', 8),\n",
       " ('boreing', 8),\n",
       " ('durring', 8),\n",
       " ('offensice', 8),\n",
       " ('ofensive', 8),\n",
       " ('authers', 8),\n",
       " ('concidered', 8),\n",
       " ('inapporiate', 8),\n",
       " ('elementry', 8),\n",
       " ('matterial', 8),\n",
       " ('cencor', 8),\n",
       " ('beleifs', 8),\n",
       " ('approprite', 8),\n",
       " ('magzine', 8),\n",
       " ('opinons', 8),\n",
       " ('shelf--that', 8),\n",
       " ('chilren', 8),\n",
       " ('finly', 8),\n",
       " ('desided', 8),\n",
       " ('computure', 8),\n",
       " ('charater', 8),\n",
       " ('time;', 8),\n",
       " ('them;', 8),\n",
       " ('\\x91peter', 8),\n",
       " ('intill', 8),\n",
       " ('finnally', 8),\n",
       " ('incase', 8),\n",
       " ('ofcourse', 8),\n",
       " ('deffinetly', 8),\n",
       " ('rideing', 8),\n",
       " ('throug', 8),\n",
       " ('computars', 8),\n",
       " ('reserch', 8),\n",
       " ('bullyed', 8),\n",
       " ('tierd', 8),\n",
       " ('bilding', 8),\n",
       " ('sertain', 8),\n",
       " ('neccesity', 8),\n",
       " ('theire', 8),\n",
       " ('seperating', 8),\n",
       " ('convienient', 8),\n",
       " ('peolple', 8),\n",
       " ('availible', 8),\n",
       " ('tecnology', 8),\n",
       " ('waisting', 8),\n",
       " ('@city1', 8),\n",
       " ('oppertunities', 8),\n",
       " ('resson', 8),\n",
       " ('intrested', 8),\n",
       " ('expirience', 8),\n",
       " ('useage', 8),\n",
       " ('deffinition', 8),\n",
       " ('othere', 8),\n",
       " ('convienent', 8),\n",
       " ('you;', 8),\n",
       " ('becomeing', 8),\n",
       " ('resturant', 8),\n",
       " ('ourselfs', 8),\n",
       " ('word-search', 7),\n",
       " ('inner-tubing', 7),\n",
       " ('soey', 7),\n",
       " ('can`t', 7),\n",
       " ('â\\x80\\x9cjohn', 7),\n",
       " ('donâ\\x80\\x99t', 7),\n",
       " ('iâ\\x80\\x99m', 7),\n",
       " ('\\x91m', 7),\n",
       " ('pacent', 7),\n",
       " ('finily', 7),\n",
       " ('paitient', 7),\n",
       " ('practicle', 7),\n",
       " ('blimbs', 7),\n",
       " ('hieght', 7),\n",
       " ('rocket-shaped', 7),\n",
       " ('obsticale', 7),\n",
       " ('dirible', 7),\n",
       " ('sacrafices', 7),\n",
       " ('habiscus', 7),\n",
       " ('narrarator', 7),\n",
       " ('rediculously', 7),\n",
       " ('inorder', 7),\n",
       " ('[the', 7),\n",
       " ('him;', 7),\n",
       " ('bestfriends', 7),\n",
       " ('segragation', 7),\n",
       " ('magaizines', 7),\n",
       " ('obsene', 7),\n",
       " ('material;', 7),\n",
       " ('differant', 7),\n",
       " ('musice', 7),\n",
       " ('offincive', 7),\n",
       " ('apporiate', 7),\n",
       " ('considerd', 7),\n",
       " ('affend', 7),\n",
       " ('provacative', 7),\n",
       " ('lanuage', 7),\n",
       " ('explict', 7),\n",
       " ('affended', 7),\n",
       " ('everynight', 7),\n",
       " ('talkes', 7),\n",
       " ('viloence', 7),\n",
       " ('launguage', 7),\n",
       " ('volgure', 7),\n",
       " ('gardian', 7),\n",
       " ('gaurdian', 7),\n",
       " ('gurdian', 7),\n",
       " ('opions', 7),\n",
       " ('libraian', 7),\n",
       " ('libraries;', 7),\n",
       " ('avaible', 7),\n",
       " ('unsensored', 7),\n",
       " ('discribe', 7),\n",
       " ('censhorship', 7),\n",
       " ('concluds', 7),\n",
       " ('minits', 7),\n",
       " ('negetive', 7),\n",
       " ('deffinitly', 7),\n",
       " ('intersting', 7),\n",
       " ('cusin', 7),\n",
       " ('inaproprate', 7),\n",
       " ('anyday', 7),\n",
       " ('dollers', 7),\n",
       " ('neccesary', 7),\n",
       " ('bigest', 7),\n",
       " ('wieght', 7),\n",
       " ('relitive', 7),\n",
       " ('knolage', 7),\n",
       " ('speek', 7),\n",
       " ('choise', 7),\n",
       " ('techknowlogy', 7),\n",
       " ('amusment', 7),\n",
       " ('stairing', 7),\n",
       " ('oppurtunities', 7),\n",
       " ('peopl', 7),\n",
       " ('absolutley', 7),\n",
       " ('minuts', 7),\n",
       " ('wrighting', 7),\n",
       " ('valueable', 7),\n",
       " ('experence', 7),\n",
       " ('everythings', 7),\n",
       " ('barly', 7),\n",
       " ('mentaly', 7),\n",
       " ('physicaly', 7),\n",
       " ('moniter', 7),\n",
       " ('agreat', 7),\n",
       " ('definitly', 7),\n",
       " ('highschoolers', 7),\n",
       " ('totaly', 7),\n",
       " ('becus', 7),\n",
       " ('simplier', 7),\n",
       " ('cought', 7),\n",
       " ('normaly', 7),\n",
       " ('lazyness', 7),\n",
       " ('apreciate', 7),\n",
       " ('oponion', 7),\n",
       " ('thas', 7),\n",
       " ('acually', 7),\n",
       " ('beatiful', 7),\n",
       " ('samething', 7),\n",
       " ('obiese', 7),\n",
       " ('positve', 7),\n",
       " ('cordenation', 7),\n",
       " ('promblems', 7),\n",
       " ('relie', 7),\n",
       " ('messanger', 7),\n",
       " ('obeseity', 7),\n",
       " ('injoy', 7),\n",
       " ('hadnt', 7),\n",
       " ('cyberbulling', 7),\n",
       " ('comptuers', 7),\n",
       " ('famly', 7),\n",
       " ('physicly', 7),\n",
       " ('recieves', 7),\n",
       " ('anyting', 7),\n",
       " ('well;', 7),\n",
       " ('studys', 7),\n",
       " ('opition', 7),\n",
       " ('senery', 7),\n",
       " ('deffinately', 7),\n",
       " ('relatioship', 6),\n",
       " ('patiencent', 6),\n",
       " ('â\\x80\\x99', 6),\n",
       " ('pacents', 6),\n",
       " ('patince', 6),\n",
       " ('patint', 6),\n",
       " ('pacint', 6),\n",
       " ('swivle', 6),\n",
       " ('dirigibels', 6),\n",
       " ('blimb', 6),\n",
       " ('glassed-in', 6),\n",
       " ('flammible', 6),\n",
       " ('poped', 6),\n",
       " ('appriciative', 6),\n",
       " ('imagrents', 6),\n",
       " ('carrers', 6),\n",
       " ('sacraficed', 6),\n",
       " ('gesse', 6),\n",
       " ('say;', 6),\n",
       " ('at-at-', 6),\n",
       " ('budds', 6),\n",
       " ('hibicus', 6),\n",
       " ('competive', 6),\n",
       " ('journy', 6),\n",
       " ('perservere', 6),\n",
       " ('[he]', 6),\n",
       " ('abanded', 6),\n",
       " ('whitch', 6),\n",
       " ('listend', 6),\n",
       " ('fufill', 6),\n",
       " ('inapporite', 6),\n",
       " ('materal', 6),\n",
       " ('aurthor', 6),\n",
       " ('librairy', 6),\n",
       " ('rateing', 6),\n",
       " ('materail', 6),\n",
       " ('offenisve', 6),\n",
       " ('audiance', 6),\n",
       " ('languge', 6),\n",
       " ('theirselves', 6),\n",
       " ('concent', 6),\n",
       " ('rascist', 6),\n",
       " ('someting', 6),\n",
       " ('carefull', 6),\n",
       " ('seperates', 6),\n",
       " ('becaused', 6),\n",
       " ('complane', 6),\n",
       " ('guidence', 6),\n",
       " ('person;', 6),\n",
       " ('pornagraphic', 6),\n",
       " ('as;', 6),\n",
       " ('dangerouse', 6),\n",
       " ('dispite', 6),\n",
       " ('about;', 6),\n",
       " ('are;', 6),\n",
       " ('experiance', 6),\n",
       " ('hopless', 6),\n",
       " ('strenght', 6),\n",
       " ('exeed', 6),\n",
       " ('eventualy', 6),\n",
       " ('contraversy', 6),\n",
       " ('peacful', 6),\n",
       " ('lastley', 6),\n",
       " ('ecspecially', 6),\n",
       " ('negativly', 6),\n",
       " ('inapproiate', 6),\n",
       " ('firend', 6),\n",
       " ('definatley', 6),\n",
       " ('acces', 6),\n",
       " ('ahve', 6),\n",
       " ('writeing', 6),\n",
       " ('fmaily', 6),\n",
       " ('heared', 6),\n",
       " ('truley', 6),\n",
       " ('relgion', 6),\n",
       " ('desicion', 6),\n",
       " ('quickley', 6),\n",
       " ('intrests', 6),\n",
       " ('there;', 6),\n",
       " ('neccessarily', 6),\n",
       " ('entertaning', 6),\n",
       " ('realtives', 6),\n",
       " ('oportunity', 6),\n",
       " ('powerpoints', 6),\n",
       " ('realitives', 6),\n",
       " ('forein', 6),\n",
       " ('oppinon', 6),\n",
       " ('technoligy', 6),\n",
       " ('moveing', 6),\n",
       " ('beutiful', 6),\n",
       " ('inapropreate', 6),\n",
       " ('wheight', 6),\n",
       " ('docters', 6),\n",
       " ('afect', 6),\n",
       " ('necesity', 6),\n",
       " ('restraunt', 6),\n",
       " ('findout', 6),\n",
       " ('exellent', 6),\n",
       " ('espicially', 6),\n",
       " ('wonderfull', 6),\n",
       " ('exersicing', 6),\n",
       " ('conected', 6),\n",
       " ('obeisity', 6),\n",
       " ('nessesary', 6),\n",
       " ('websit', 6),\n",
       " ('socitey', 6),\n",
       " ('apointment', 6),\n",
       " ('exausted', 6),\n",
       " ('harrased', 6),\n",
       " ('whatch', 6),\n",
       " ('somepeople', 6),\n",
       " ('attatched', 6),\n",
       " ('bacause', 6),\n",
       " ('anouther', 6),\n",
       " ('adicting', 6),\n",
       " ('websights', 6),\n",
       " ('youself', 6),\n",
       " ('thease', 6),\n",
       " ('piont', 6),\n",
       " ('lern', 6),\n",
       " ('exercizing', 6),\n",
       " ('parrents', 6),\n",
       " ('convinent', 6),\n",
       " ('reconize', 6),\n",
       " ('ohter', 6),\n",
       " ('palying', 6),\n",
       " ('easer', 6),\n",
       " ('showes', 6),\n",
       " ('thngs', 6),\n",
       " ('comunicating', 6),\n",
       " ('forgein', 6),\n",
       " ('helpul', 6),\n",
       " ('myspce', 6),\n",
       " ('defenetly', 6),\n",
       " ('wacth', 6),\n",
       " ('friends;', 6),\n",
       " ('wasteing', 6),\n",
       " ('goind', 6),\n",
       " ('facebooks', 6),\n",
       " ('laughters', 5),\n",
       " ('other;', 5),\n",
       " ('boyfriend/girlfriend', 5),\n",
       " ('farted', 5),\n",
       " ('whate', 5),\n",
       " ('rollor', 5),\n",
       " ('cernal', 5),\n",
       " ('hospitle', 5),\n",
       " ('replyed', 5),\n",
       " ('couldnâ\\x80\\x99t', 5),\n",
       " ('payshent', 5),\n",
       " ('thatâ\\x80\\x99s', 5),\n",
       " ('patiente', 5),\n",
       " ('didnâ\\x80\\x99t', 5),\n",
       " ('moorning', 5),\n",
       " ('buiders', 5),\n",
       " ('zepplins', 5),\n",
       " ('steelframe', 5),\n",
       " ('densley', 5),\n",
       " ('teathered', 5),\n",
       " ('was;', 5),\n",
       " ('thousand-', 5),\n",
       " ('itself;', 5),\n",
       " ('safetly', 5),\n",
       " ('memmoir', 5),\n",
       " ('paragraf', 5),\n",
       " ('happness', 5),\n",
       " ('familey', 5),\n",
       " ('nonstalgic', 5),\n",
       " ('parents]', 5),\n",
       " ('memor', 5),\n",
       " ('grattitude', 5),\n",
       " ('imagrants', 5),\n",
       " ('immagrated', 5),\n",
       " ('blonde-brick', 5),\n",
       " ('at-at', 5),\n",
       " ('saeng\\x91s', 5),\n",
       " ('lisence', 5),\n",
       " ('faeng-noi', 5),\n",
       " ('buding', 5),\n",
       " ('strenghth', 5),\n",
       " ('is-it', 5),\n",
       " ('[1', 5),\n",
       " ('perservering', 5),\n",
       " ('rollar', 5),\n",
       " ('thrist', 5),\n",
       " ('snake-it', 5),\n",
       " ('afected', 5),\n",
       " ('abandond', 5),\n",
       " ('\\x91s', 5),\n",
       " ('snake-', 5),\n",
       " ('diamondback-blocked', 5),\n",
       " ('cylist', 5),\n",
       " ('\\x91town', 5),\n",
       " ('luckly', 5),\n",
       " ('apporpriate', 5),\n",
       " ('like;', 5),\n",
       " ('memeries', 5),\n",
       " ('cursewords', 5),\n",
       " ('book/magazine', 5),\n",
       " ('worng', 5),\n",
       " ('complian', 5),\n",
       " ('meterial', 5),\n",
       " ('accomidate', 5),\n",
       " ('bookes', 5),\n",
       " ('unapropriate', 5),\n",
       " ('non-', 5),\n",
       " ('lable', 5),\n",
       " ('eightteen', 5),\n",
       " ('lauguage', 5),\n",
       " ('shelf--', 5),\n",
       " ('libarian', 5),\n",
       " ('worrie', 5),\n",
       " ('provokative', 5),\n",
       " ('sheleves', 5),\n",
       " ('famliy', 5),\n",
       " ('accomadate', 5),\n",
       " ('magizens', 5),\n",
       " ('offenive', 5),\n",
       " ('read;', 5),\n",
       " ('grusome', 5),\n",
       " ('censered', 5),\n",
       " ('right;', 5),\n",
       " ('inmature', 5),\n",
       " ('offenseive', 5),\n",
       " ('sensorship', 5),\n",
       " ('thing;', 5),\n",
       " ('sheild', 5),\n",
       " ('regaurdless', 5),\n",
       " ('censoship', 5),\n",
       " ('neccasary', 5),\n",
       " ('intersted', 5),\n",
       " ('privelages', 5),\n",
       " ('againts', 5),\n",
       " ('parnets', 5),\n",
       " ('athiest', 5),\n",
       " ('contraversial', 5),\n",
       " ('offensve', 5),\n",
       " ('esle', 5),\n",
       " ('censoreship', 5),\n",
       " ('expierences', 5),\n",
       " ('instence', 5),\n",
       " ('differnet', 5),\n",
       " ('exceptable', 5),\n",
       " ('oppenion', 5),\n",
       " ('catagorized', 5),\n",
       " ('inforced', 5),\n",
       " ('not;', 5),\n",
       " ('innocense', 5),\n",
       " ('libarys', 5),\n",
       " ('censorhip', 5),\n",
       " ('pornagraphy', 5),\n",
       " ('diffrence', 5),\n",
       " ('writter', 5),\n",
       " ('thigs', 5),\n",
       " ('hungery', 5),\n",
       " ('preasure', 5),\n",
       " ('tyring', 5),\n",
       " ('lastely', 5),\n",
       " ('exept', 5),\n",
       " ('proble', 5),\n",
       " ('faild', 5),\n",
       " ('pleasent', 5),\n",
       " ('aparent', 5),\n",
       " ('bussiness', 5),\n",
       " ('privelage', 5),\n",
       " ('interfer', 5),\n",
       " ('concider', 5),\n",
       " ('akward', 5),\n",
       " ('biulding', 5),\n",
       " ('explaing', 5),\n",
       " ('buisiness', 5),\n",
       " ('sociaty', 5),\n",
       " ('to;', 5),\n",
       " ('libarary', 5),\n",
       " ('therfore', 5),\n",
       " ('pysical', 5),\n",
       " ('school;', 5),\n",
       " ('benefical', 5),\n",
       " ('hault', 5),\n",
       " ('seting', 5),\n",
       " ('seens', 5),\n",
       " ('engry', 5),\n",
       " ('aroung', 5),\n",
       " ('ecersise', 5),\n",
       " ('difrent', 5),\n",
       " ('easyier', 5),\n",
       " ('actuly', 5),\n",
       " ('conect', 5),\n",
       " ('adictive', 5),\n",
       " ('telivision', 5),\n",
       " ('thaught', 5),\n",
       " ('perents', 5),\n",
       " ('us;', 5),\n",
       " ('lisen', 5),\n",
       " ('liveing', 5),\n",
       " ('distroyed', 5),\n",
       " ('intenet', 5),\n",
       " ('withought', 5),\n",
       " ('penpals', 5),\n",
       " ('neice', 5),\n",
       " ('excersicing', 5),\n",
       " ('cornation', 5),\n",
       " ('pregnacy', 5),\n",
       " ('outragous', 5),\n",
       " ('greates', 5),\n",
       " ('leaft', 5),\n",
       " ('explaines', 5),\n",
       " ('awnser', 5),\n",
       " ('exircise', 5),\n",
       " ('wnat', 5),\n",
       " ('familier', 5),\n",
       " ('begginning', 5),\n",
       " ('neccessity', 5),\n",
       " ('busnesses', 5),\n",
       " ('definetely', 5),\n",
       " ('argueing', 5),\n",
       " ('importent', 5),\n",
       " ('practicly', 5),\n",
       " ('constanly', 5),\n",
       " ('out;', 5),\n",
       " ('acidents', 5),\n",
       " ('travling', 5),\n",
       " ('computers;', 5),\n",
       " ('aldults', 5),\n",
       " ('recipies', 5),\n",
       " ('nessisary', 5),\n",
       " ('societys', 5),\n",
       " ('on;', 5),\n",
       " ('positivly', 5),\n",
       " ('accesible', 5),\n",
       " ('allready', 5),\n",
       " ('eaiser', 5),\n",
       " ('scientest', 5),\n",
       " ('corrdination', 5),\n",
       " ('book;', 5),\n",
       " ('preditors', 5),\n",
       " ('proffesor', 5),\n",
       " ('solitare', 5),\n",
       " ('before;', 5),\n",
       " ('opertunities', 5),\n",
       " ('happends', 5),\n",
       " ('-peter', 5),\n",
       " ('nessecary', 5),\n",
       " ('understant', 5),\n",
       " ('childre', 5),\n",
       " ('coumputers', 5),\n",
       " ('bad;', 5),\n",
       " ('youve', 5),\n",
       " ('cancled', 5),\n",
       " ('choosen', 5),\n",
       " ('vocab', 5),\n",
       " ('anythin', 5),\n",
       " ('exsist', 5),\n",
       " ('thnk', 5),\n",
       " ('ocmputer', 5),\n",
       " ('teached', 5),\n",
       " ('compuer', 5),\n",
       " ('libery', 5),\n",
       " ('softwear', 5),\n",
       " ('dosnt', 5),\n",
       " ('olny', 5),\n",
       " ('futhermore', 5),\n",
       " ('resturants', 5),\n",
       " ('orginized', 5),\n",
       " ('hastle', 5),\n",
       " ('cyberbullied', 5),\n",
       " ('ti-rent', 4),\n",
       " ('towl', 4),\n",
       " ('fricken', 4),\n",
       " ('toung', 4),\n",
       " ('all-peter', 4),\n",
       " ('girlfreind', 4),\n",
       " ('laugh;', 4),\n",
       " ('lt;peter', 4),\n",
       " ('cout', 4),\n",
       " ('step-dad', 4),\n",
       " ('kickline', 4),\n",
       " ('surgey', 4),\n",
       " ('minuites', 4),\n",
       " ('iâ\\x80\\x99ll', 4),\n",
       " ('patientce', 4),\n",
       " ('grocerys', 4),\n",
       " ('pations', 4),\n",
       " ('coner', 4),\n",
       " ('sharae', 4),\n",
       " ('atime', 4),\n",
       " ('marrie', 4),\n",
       " ('chees', 4),\n",
       " ('cuzins', 4),\n",
       " ('patence', 4),\n",
       " ('madichian', 4),\n",
       " ('compition', 4),\n",
       " ('dirrigible', 4),\n",
       " ('flamibility', 4),\n",
       " ('185-foot', 4),\n",
       " ('baloon', 4),\n",
       " ('dirgible', 4),\n",
       " ('obstacal', 4),\n",
       " ('dirigibe', 4),\n",
       " ('sixty-thousand', 4),\n",
       " ('obstecles', 4),\n",
       " ('building]', 4),\n",
       " ('attemp', 4),\n",
       " ('refule', 4),\n",
       " ('nature;', 4),\n",
       " ('architecs', 4),\n",
       " ('architechs', 4),\n",
       " ('strees', 4),\n",
       " ('homyness', 4),\n",
       " ('undefind', 4),\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = makeEssayArr(replaceCommon=True, removeSW=False)\n",
    "vocab = build_vocab(sentences)\n",
    "check_coverage(vocab,glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12701,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setID():\n",
    "    id=[]\n",
    "    for index, df in enumerate(data.essay):\n",
    "        id.append(index)\n",
    "    return id\n",
    "data['id']=setID()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2vec(essay_id):\n",
    "    size = len(sentences[essay_id])\n",
    "    found = 0\n",
    "    embedding = np.zeros(300,dtype=\"float32\")\n",
    "    for word in sentences[essay_id]:\n",
    "        if word in glove:\n",
    "            found+=1\n",
    "            embedding += glove[word]\n",
    "    embedding = np.divide(embedding,found)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['embeddings'] = data['id'].apply(lambda x: convert2vec(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "      <th>id</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12971</th>\n",
       "      <td>21626</td>\n",
       "      <td>8</td>\n",
       "      <td>In most stories mothers and daughters are eit...</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12696</td>\n",
       "      <td>[-0.122094214, 0.09524214, -0.053078335, -0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12972</th>\n",
       "      <td>21628</td>\n",
       "      <td>8</td>\n",
       "      <td>I never understood the meaning laughter is th...</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12697</td>\n",
       "      <td>[-0.124869, 0.091405176, -0.045465734, -0.0824...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>21629</td>\n",
       "      <td>8</td>\n",
       "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12698</td>\n",
       "      <td>[-0.09099377, 0.08082998, -0.04143547, -0.1448...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12974</th>\n",
       "      <td>21630</td>\n",
       "      <td>8</td>\n",
       "      <td>Trippin' on fen...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12699</td>\n",
       "      <td>[-0.10467531, 0.061440624, -0.046567135, -0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12975</th>\n",
       "      <td>21633</td>\n",
       "      <td>8</td>\n",
       "      <td>Many people believe that laughter can improve...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12700</td>\n",
       "      <td>[-0.14170836, 0.11989354, -0.034562092, -0.143...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id  essay_set                                              essay  \\\n",
       "12971     21626          8   In most stories mothers and daughters are eit...   \n",
       "12972     21628          8   I never understood the meaning laughter is th...   \n",
       "12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
       "12974     21630          8                                 Trippin' on fen...   \n",
       "12975     21633          8   Many people believe that laughter can improve...   \n",
       "\n",
       "       rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "12971              17              18             NaN             35   \n",
       "12972              15              17             NaN             32   \n",
       "12973              20              26            40.0             40   \n",
       "12974              20              20             NaN             40   \n",
       "12975              20              20             NaN             40   \n",
       "\n",
       "       rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait5  \\\n",
       "12971             NaN             NaN            NaN  ...            4.0   \n",
       "12972             NaN             NaN            NaN  ...            4.0   \n",
       "12973             NaN             NaN            NaN  ...            5.0   \n",
       "12974             NaN             NaN            NaN  ...            4.0   \n",
       "12975             NaN             NaN            NaN  ...            4.0   \n",
       "\n",
       "       rater2_trait6  rater3_trait1  rater3_trait2  rater3_trait3  \\\n",
       "12971            3.0            NaN            NaN            NaN   \n",
       "12972            3.0            NaN            NaN            NaN   \n",
       "12973            5.0            4.0            4.0            4.0   \n",
       "12974            4.0            NaN            NaN            NaN   \n",
       "12975            4.0            NaN            NaN            NaN   \n",
       "\n",
       "       rater3_trait4  rater3_trait5  rater3_trait6     id  \\\n",
       "12971            NaN            NaN            NaN  12696   \n",
       "12972            NaN            NaN            NaN  12697   \n",
       "12973            4.0            4.0            4.0  12698   \n",
       "12974            NaN            NaN            NaN  12699   \n",
       "12975            NaN            NaN            NaN  12700   \n",
       "\n",
       "                                              embeddings  \n",
       "12971  [-0.122094214, 0.09524214, -0.053078335, -0.10...  \n",
       "12972  [-0.124869, 0.091405176, -0.045465734, -0.0824...  \n",
       "12973  [-0.09099377, 0.08082998, -0.04143547, -0.1448...  \n",
       "12974  [-0.10467531, 0.061440624, -0.046567135, -0.09...  \n",
       "12975  [-0.14170836, 0.11989354, -0.034562092, -0.143...  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "      <th>id</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.1852118, 0.06012019, -0.029879754, -0.1156...</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.1839048, 0.10882854, -0.027344918, -0.1496...</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.16473815, 0.106056325, 0.0016457571, -0.16...</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.17554235, 0.11150211, -0.044427224, -0.169...</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.18809283, 0.108385086, -0.053500302, -0.16...</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait6  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "3             NaN             NaN            NaN  ...            NaN   \n",
       "4             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater3_trait1  rater3_trait2  rater3_trait3  rater3_trait4  rater3_trait5  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait6  id                                         embeddings  \\\n",
       "0            NaN   0  [-0.1852118, 0.06012019, -0.029879754, -0.1156...   \n",
       "1            NaN   1  [-0.1839048, 0.10882854, -0.027344918, -0.1496...   \n",
       "2            NaN   2  [-0.16473815, 0.106056325, 0.0016457571, -0.16...   \n",
       "3            NaN   3  [-0.17554235, 0.11150211, -0.044427224, -0.169...   \n",
       "4            NaN   4  [-0.18809283, 0.108385086, -0.053500302, -0.16...   \n",
       "\n",
       "   final_score  \n",
       "0         40.0  \n",
       "1         45.0  \n",
       "2         35.0  \n",
       "3         50.0  \n",
       "4         40.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nndata = data.copy()\n",
    "nndata['final_score'] = nndata.apply(lambda row: row['domain1_score'] if row['essay_set']!=2 else row['domain1_score'] + row['domain2_score'], axis=1)\n",
    "mul = [5,6,20,20,15,15,2,1]\n",
    "nndata['final_score'] = nndata.apply(lambda row: row['final_score']*mul[row['essay_set']-1], axis=1)\n",
    "# nndata.groupby('essay_set').describe()\n",
    "nndata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nndata = nndata[['embeddings', 'final_score']]\n",
    "train_data = nndata.sample(frac=0.85,random_state=0)\n",
    "test_data = nndata.drop(train_data.index)\n",
    "train_labels = train_data.pop('final_score')\n",
    "test_labels = test_data.pop('final_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(128, activation=tf.nn.relu, input_shape=np.shape(train_data.iloc[0]['embeddings'])),\n",
    "    layers.Dense(64, activation=tf.nn.relu),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model.compile(loss='mean_squared_error',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 46,849\n",
      "Trainable params: 46,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_arr = np.zeros((train_data.size,300),dtype=\"float32\")\n",
    "for i, emb in enumerate(train_data['embeddings']):\n",
    "    train_data_arr[i]=emb\n",
    "train_labels_arr = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9716 samples, validate on 1080 samples\n",
      "WARNING:tensorflow:From /home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n",
      "9716/9716 [==============================] - 4s 404us/sample - loss: 259.0710 - mean_absolute_error: 12.2641 - mean_squared_error: 259.0709 - val_loss: 174.8702 - val_mean_absolute_error: 9.9722 - val_mean_squared_error: 174.8702\n",
      "Epoch 2/2\n",
      "9716/9716 [==============================] - 1s 135us/sample - loss: 148.9499 - mean_absolute_error: 9.3732 - mean_squared_error: 148.9499 - val_loss: 156.3679 - val_mean_absolute_error: 9.3876 - val_mean_squared_error: 156.3679\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data_arr, train_labels_arr, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
