{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "import spacy; from spacy.lang.en import English; nlp = English()\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav_pro/SchoolSystem/models/essay/utils.py:6: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  data['illegible']=data.essay.str.contains('(\\?\\?\\?|illegible|not legible)')\n"
     ]
    }
   ],
   "source": [
    "data = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>rater1_trait1</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12701.000000</td>\n",
       "      <td>12701.000000</td>\n",
       "      <td>12701.000000</td>\n",
       "      <td>12701.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>12701.000000</td>\n",
       "      <td>1799.000000</td>\n",
       "      <td>1799.000000</td>\n",
       "      <td>1799.000000</td>\n",
       "      <td>2055.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2055.000000</td>\n",
       "      <td>2055.000000</td>\n",
       "      <td>722.000000</td>\n",
       "      <td>722.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10146.245020</td>\n",
       "      <td>4.129832</td>\n",
       "      <td>4.057791</td>\n",
       "      <td>4.068341</td>\n",
       "      <td>37.828125</td>\n",
       "      <td>6.635226</td>\n",
       "      <td>3.334074</td>\n",
       "      <td>3.330739</td>\n",
       "      <td>3.334074</td>\n",
       "      <td>2.504136</td>\n",
       "      <td>...</td>\n",
       "      <td>2.708029</td>\n",
       "      <td>2.773723</td>\n",
       "      <td>3.778393</td>\n",
       "      <td>3.590028</td>\n",
       "      <td>3.945312</td>\n",
       "      <td>3.890625</td>\n",
       "      <td>4.078125</td>\n",
       "      <td>3.992188</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>3.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6266.038381</td>\n",
       "      <td>2.123600</td>\n",
       "      <td>4.205748</td>\n",
       "      <td>4.259040</td>\n",
       "      <td>5.240829</td>\n",
       "      <td>8.945280</td>\n",
       "      <td>0.729263</td>\n",
       "      <td>0.726967</td>\n",
       "      <td>0.729263</td>\n",
       "      <td>1.229647</td>\n",
       "      <td>...</td>\n",
       "      <td>1.168146</td>\n",
       "      <td>1.061814</td>\n",
       "      <td>0.689271</td>\n",
       "      <td>0.693389</td>\n",
       "      <td>0.643668</td>\n",
       "      <td>0.630390</td>\n",
       "      <td>0.622535</td>\n",
       "      <td>0.509687</td>\n",
       "      <td>0.538845</td>\n",
       "      <td>0.603417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4372.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9941.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15513.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21633.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           essay_id     essay_set  rater1_domain1  rater2_domain1  \\\n",
       "count  12701.000000  12701.000000    12701.000000    12701.000000   \n",
       "mean   10146.245020      4.129832        4.057791        4.068341   \n",
       "std     6266.038381      2.123600        4.205748        4.259040   \n",
       "min        1.000000      1.000000        0.000000        0.000000   \n",
       "25%     4372.000000      2.000000        2.000000        2.000000   \n",
       "50%     9941.000000      4.000000        3.000000        3.000000   \n",
       "75%    15513.000000      6.000000        4.000000        4.000000   \n",
       "max    21633.000000      8.000000       30.000000       30.000000   \n",
       "\n",
       "       rater3_domain1  domain1_score  rater1_domain2  rater2_domain2  \\\n",
       "count      128.000000   12701.000000     1799.000000     1799.000000   \n",
       "mean        37.828125       6.635226        3.334074        3.330739   \n",
       "std          5.240829       8.945280        0.729263        0.726967   \n",
       "min         20.000000       0.000000        1.000000        1.000000   \n",
       "25%         36.000000       2.000000        3.000000        3.000000   \n",
       "50%         40.000000       3.000000        3.000000        3.000000   \n",
       "75%         40.000000       8.000000        4.000000        4.000000   \n",
       "max         50.000000      60.000000        4.000000        4.000000   \n",
       "\n",
       "       domain2_score  rater1_trait1  ...  rater2_trait3  rater2_trait4  \\\n",
       "count    1799.000000    2055.000000  ...    2055.000000    2055.000000   \n",
       "mean        3.334074       2.504136  ...       2.708029       2.773723   \n",
       "std         0.729263       1.229647  ...       1.168146       1.061814   \n",
       "min         1.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         3.000000       2.000000  ...       2.000000       2.000000   \n",
       "50%         3.000000       2.000000  ...       2.000000       3.000000   \n",
       "75%         4.000000       3.000000  ...       4.000000       4.000000   \n",
       "max         4.000000       6.000000  ...       6.000000       6.000000   \n",
       "\n",
       "       rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "count     722.000000     722.000000     128.000000     128.000000   \n",
       "mean        3.778393       3.590028       3.945312       3.890625   \n",
       "std         0.689271       0.693389       0.643668       0.630390   \n",
       "min         1.000000       1.000000       2.000000       2.000000   \n",
       "25%         3.000000       3.000000       4.000000       4.000000   \n",
       "50%         4.000000       4.000000       4.000000       4.000000   \n",
       "75%         4.000000       4.000000       4.000000       4.000000   \n",
       "max         6.000000       6.000000       6.000000       6.000000   \n",
       "\n",
       "       rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "count     128.000000     128.000000     128.000000     128.000000  \n",
       "mean        4.078125       3.992188       3.843750       3.617188  \n",
       "std         0.622535       0.509687       0.538845       0.603417  \n",
       "min         2.000000       3.000000       2.000000       2.000000  \n",
       "25%         4.000000       4.000000       4.000000       3.000000  \n",
       "50%         4.000000       4.000000       4.000000       4.000000  \n",
       "75%         4.000000       4.000000       4.000000       4.000000  \n",
       "max         6.000000       6.000000       5.000000       5.000000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = data[[\"essay_id\", \"essay_set\", \"essay\", \"domain2_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "main[\"score\"] = data['domain1_score']\n",
    "main.score=main.apply(lambda x: x['score'] if x['essay_set']!=2 else x['score']+x['domain2_score'], axis=1)\n",
    "main.score=main.apply(lambda x: x['score'] if x['essay_set']!=2 and x['essay_set']!=1 else x['score']-2, axis=1)\n",
    "main = main.drop([\"domain2_score\"], axis=1)\n",
    "mul = np.array([12,15,40,40,30,30,4,2])/120\n",
    "main['score'] = main.apply(lambda row: row['score']*mul[row['essay_set']-1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">essay_id</th>\n",
       "      <th colspan=\"8\" halign=\"left\">score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>essay_set</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1782.0</td>\n",
       "      <td>894.752525</td>\n",
       "      <td>515.950660</td>\n",
       "      <td>1.0</td>\n",
       "      <td>449.25</td>\n",
       "      <td>894.5</td>\n",
       "      <td>1341.75</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>1782.0</td>\n",
       "      <td>0.652694</td>\n",
       "      <td>0.153788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1799.0</td>\n",
       "      <td>3877.747638</td>\n",
       "      <td>519.797850</td>\n",
       "      <td>2978.0</td>\n",
       "      <td>3427.50</td>\n",
       "      <td>3878.0</td>\n",
       "      <td>4327.50</td>\n",
       "      <td>4777.0</td>\n",
       "      <td>1799.0</td>\n",
       "      <td>0.593663</td>\n",
       "      <td>0.173149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1699.0</td>\n",
       "      <td>6842.185403</td>\n",
       "      <td>499.394444</td>\n",
       "      <td>5978.0</td>\n",
       "      <td>6409.50</td>\n",
       "      <td>6842.0</td>\n",
       "      <td>7273.50</td>\n",
       "      <td>7708.0</td>\n",
       "      <td>1699.0</td>\n",
       "      <td>0.616441</td>\n",
       "      <td>0.271374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1761.0</td>\n",
       "      <td>9750.014764</td>\n",
       "      <td>513.547831</td>\n",
       "      <td>8863.0</td>\n",
       "      <td>9305.00</td>\n",
       "      <td>9751.0</td>\n",
       "      <td>10194.00</td>\n",
       "      <td>10642.0</td>\n",
       "      <td>1761.0</td>\n",
       "      <td>0.476245</td>\n",
       "      <td>0.313552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1805.0</td>\n",
       "      <td>12729.000000</td>\n",
       "      <td>521.202936</td>\n",
       "      <td>11827.0</td>\n",
       "      <td>12278.00</td>\n",
       "      <td>12729.0</td>\n",
       "      <td>13180.00</td>\n",
       "      <td>13631.0</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>0.602216</td>\n",
       "      <td>0.242705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1800.0</td>\n",
       "      <td>15733.500000</td>\n",
       "      <td>519.759560</td>\n",
       "      <td>14834.0</td>\n",
       "      <td>15283.75</td>\n",
       "      <td>15733.5</td>\n",
       "      <td>16183.25</td>\n",
       "      <td>16633.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.242658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1333.0</td>\n",
       "      <td>18696.284321</td>\n",
       "      <td>499.403100</td>\n",
       "      <td>17834.0</td>\n",
       "      <td>18259.00</td>\n",
       "      <td>18705.0</td>\n",
       "      <td>19124.00</td>\n",
       "      <td>19563.0</td>\n",
       "      <td>1333.0</td>\n",
       "      <td>0.533858</td>\n",
       "      <td>0.153664</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>722.0</td>\n",
       "      <td>21168.975069</td>\n",
       "      <td>262.783588</td>\n",
       "      <td>20716.0</td>\n",
       "      <td>20940.50</td>\n",
       "      <td>21163.5</td>\n",
       "      <td>21396.25</td>\n",
       "      <td>21633.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.615974</td>\n",
       "      <td>0.095887</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          essay_id                                                        \\\n",
       "             count          mean         std      min       25%      50%   \n",
       "essay_set                                                                  \n",
       "1           1782.0    894.752525  515.950660      1.0    449.25    894.5   \n",
       "2           1799.0   3877.747638  519.797850   2978.0   3427.50   3878.0   \n",
       "3           1699.0   6842.185403  499.394444   5978.0   6409.50   6842.0   \n",
       "4           1761.0   9750.014764  513.547831   8863.0   9305.00   9751.0   \n",
       "5           1805.0  12729.000000  521.202936  11827.0  12278.00  12729.0   \n",
       "6           1800.0  15733.500000  519.759560  14834.0  15283.75  15733.5   \n",
       "7           1333.0  18696.284321  499.403100  17834.0  18259.00  18705.0   \n",
       "8            722.0  21168.975069  262.783588  20716.0  20940.50  21163.5   \n",
       "\n",
       "                               score                                          \\\n",
       "                75%      max   count      mean       std       min       25%   \n",
       "essay_set                                                                      \n",
       "1           1341.75   1787.0  1782.0  0.652694  0.153788  0.000000  0.600000   \n",
       "2           4327.50   4777.0  1799.0  0.593663  0.173149  0.000000  0.500000   \n",
       "3           7273.50   7708.0  1699.0  0.616441  0.271374  0.000000  0.333333   \n",
       "4          10194.00  10642.0  1761.0  0.476245  0.313552  0.000000  0.333333   \n",
       "5          13180.00  13631.0  1805.0  0.602216  0.242705  0.000000  0.500000   \n",
       "6          16183.25  16633.0  1800.0  0.680000  0.242658  0.000000  0.500000   \n",
       "7          19124.00  19563.0  1333.0  0.533858  0.153664  0.066667  0.433333   \n",
       "8          21396.25  21633.0   722.0  0.615974  0.095887  0.166667  0.550000   \n",
       "\n",
       "                                    \n",
       "                50%       75%  max  \n",
       "essay_set                           \n",
       "1          0.600000  0.800000  1.0  \n",
       "2          0.625000  0.750000  1.0  \n",
       "3          0.666667  0.666667  1.0  \n",
       "4          0.333333  0.666667  1.0  \n",
       "5          0.500000  0.750000  1.0  \n",
       "6          0.750000  0.750000  1.0  \n",
       "7          0.533333  0.633333  0.8  \n",
       "8          0.616667  0.666667  1.0  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.groupby('essay_set').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "w2vModel = Word2Vec.load('Essayw2v.model')\n",
    "vocab = set(w2vModel.wv.vocab)\n",
    "dic = w2vModel.wv\n",
    "w2v = dict(zip(w2vModel.wv.index2word, w2vModel.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2tokens(essay):\n",
    "    essay = basicClean(essay)\n",
    "    essay = replaceNER(essay)\n",
    "    essay = nlp(essay)\n",
    "#     essay = [token.text for token in essay if ((not token.is_punct) and (not token.is_stop))]\n",
    "    essay = [token.text for token in essay if (not token.is_punct)]\n",
    "    return essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12701/12701 [00:15<00:00, 825.83it/s] \n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "main['tokenize'] = main['essay'].progress_apply(lambda x: convert2tokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/keras_preprocessing/text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42443 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(nb_words=len(vocab))\n",
    "tokenizer.fit_on_texts(main['tokenize'])\n",
    "main['sequence'] = tokenizer.texts_to_sequences(main['tokenize'])\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaxSequence = max([len(seq) for seq in data['sequence']])\n",
    "MaxSequence = 1200\n",
    "tqdm.pandas()\n",
    "main['pad_seq']=list(pad_sequences(main['sequence'], maxlen=MaxSequence))\n",
    "# data['padSequence'] = data['sequence'].progress_apply(lambda seq: pad_sequences([seq],maxlen=MaxSequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['essay_id', 'essay_set', 'essay', 'rater1_domain1', 'rater2_domain1',\n",
       "       'rater3_domain1', 'domain1_score', 'rater1_domain2', 'rater2_domain2',\n",
       "       'domain2_score', 'rater1_trait1', 'rater1_trait2', 'rater1_trait3',\n",
       "       'rater1_trait4', 'rater1_trait5', 'rater1_trait6', 'rater2_trait1',\n",
       "       'rater2_trait2', 'rater2_trait3', 'rater2_trait4', 'rater2_trait5',\n",
       "       'rater2_trait6', 'rater3_trait1', 'rater3_trait2', 'rater3_trait3',\n",
       "       'rater3_trait4', 'rater3_trait5', 'rater3_trait6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "p7 = data.loc[data['essay_set']==7]\n",
    "p8 = data.loc[data['essay_set']==8]\n",
    "p7[\"Essay ID\"] = p7['essay_id']\n",
    "p8[\"Essay ID\"] = p8['essay_id']\n",
    "p7['Content'] = p7['rater1_trait1']/3\n",
    "p7['Organization'] = p7['rater1_trait2']/3\n",
    "p7['Language'] = p7['rater1_trait3']/3\n",
    "p7['Conventions'] = p7['rater1_trait4']/3\n",
    "p7 = p7[[\"Essay ID\", \"Content\", \"Organization\", \"Language\", \"Conventions\"]]\n",
    "p8['Content'] = p8['rater1_trait1']-1/5\n",
    "p8['Organization'] = p8['rater1_trait2']-1/5\n",
    "p8['Word Choice'] = p8['rater1_trait4']-1/5\n",
    "p8['Sentence Fluency'] = p8['rater1_trait5']-1/5\n",
    "p8['Conventions'] = p8['rater1_trait6']-1/5\n",
    "p8 = p8[[\"Essay ID\", \"Content\", \"Organization\", \"Word Choice\", \"Sentence Fluency\", 'Conventions']]\n",
    "# data['Organization'] = data['rater1_trait1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "           EssayID      Content  Organization  Word Choice  Sentence Fluency  \\\n",
      "count  1783.000000  1783.000000   1783.000000  1783.000000       1783.000000   \n",
      "mean    894.310151     3.846887      3.737521     3.679192          3.762759   \n",
      "std     516.143993     0.991320      0.950858     0.966469          0.968832   \n",
      "min       1.000000     1.000000      1.000000     1.000000          1.000000   \n",
      "25%     448.500000     3.000000      3.000000     3.000000          3.000000   \n",
      "50%     894.000000     4.000000      4.000000     4.000000          4.000000   \n",
      "75%    1341.500000     4.000000      4.000000     4.000000          4.000000   \n",
      "max    1787.000000     6.000000      6.000000     6.000000          6.000000   \n",
      "\n",
      "       Conventions  \n",
      "count  1783.000000  \n",
      "mean      3.737521  \n",
      "std       0.948494  \n",
      "min       1.000000  \n",
      "25%       3.000000  \n",
      "50%       4.000000  \n",
      "75%       4.000000  \n",
      "max       6.000000  \n",
      "2\n",
      "          Essay ID      Content  Organization  Word Choice  Sentence Fluency  \\\n",
      "count  1800.000000  1800.000000   1800.000000  1800.000000       1800.000000   \n",
      "mean   3877.494444     3.220000      3.043333     3.111667          3.332778   \n",
      "std     519.754400     1.165771      1.128887     1.120965          1.050071   \n",
      "min    2978.000000     1.000000      1.000000     1.000000          1.000000   \n",
      "25%    3427.750000     2.000000      2.000000     2.000000          3.000000   \n",
      "50%    3877.500000     3.000000      3.000000     3.000000          3.000000   \n",
      "75%    4327.250000     4.000000      4.000000     4.000000          4.000000   \n",
      "max    4777.000000     6.000000      6.000000     6.000000          6.000000   \n",
      "\n",
      "       Conventions  \n",
      "count  1800.000000  \n",
      "mean      3.132778  \n",
      "std       1.085368  \n",
      "min       1.000000  \n",
      "25%       2.000000  \n",
      "50%       3.000000  \n",
      "75%       4.000000  \n",
      "max       6.000000  \n",
      "3\n",
      "          Essay ID      Content  Prompt Adherence     Language  Narrativity\n",
      "count  1726.000000  1726.000000       1726.000000  1726.000000  1726.000000\n",
      "mean   6843.016222     1.434531          1.478563     1.472190     1.440904\n",
      "std     499.809908     0.838944          0.876325     0.846533     0.893608\n",
      "min    5978.000000     0.000000          0.000000     0.000000     0.000000\n",
      "25%    6410.250000     1.000000          1.000000     1.000000     1.000000\n",
      "50%    6842.500000     2.000000          2.000000     2.000000     1.000000\n",
      "75%    7275.750000     2.000000          2.000000     2.000000     2.000000\n",
      "max    7708.000000     3.000000          3.000000     3.000000     3.000000\n",
      "4\n",
      "           Essay ID      Content  Prompt Adherence     Language  Narrativity\n",
      "count   1772.000000  1772.000000       1772.000000  1772.000000  1772.000000\n",
      "mean    9751.358916     1.108916          1.099887     1.059819     1.209932\n",
      "std      513.750550     0.970479          0.943736     0.876205     0.990612\n",
      "min     8863.000000     0.000000          0.000000     0.000000     0.000000\n",
      "25%     9306.750000     0.000000          0.000000     0.000000     0.000000\n",
      "50%     9751.500000     1.000000          1.000000     1.000000     1.000000\n",
      "75%    10196.250000     2.000000          2.000000     2.000000     2.000000\n",
      "max    10642.000000     3.000000          3.000000     3.000000     3.000000\n",
      "5\n",
      "           Essay ID      Content  Prompt Adherence     Language  Narrativity\n",
      "count   1805.000000  1805.000000       1805.000000  1805.000000  1805.000000\n",
      "mean   12729.000000     1.884211          2.034349     2.236565     2.029363\n",
      "std      521.202936     1.001883          1.056043     0.938812     0.903137\n",
      "min    11827.000000     0.000000          0.000000     0.000000     0.000000\n",
      "25%    12278.000000     1.000000          1.000000     2.000000     2.000000\n",
      "50%    12729.000000     2.000000          2.000000     2.000000     2.000000\n",
      "75%    13180.000000     3.000000          3.000000     3.000000     3.000000\n",
      "max    13631.000000     4.000000          4.000000     4.000000     4.000000\n",
      "6\n",
      "          Essay ID      Content  Prompt Adherence     Language  Narrativity\n",
      "count   1800.00000  1800.000000       1800.000000  1800.000000  1800.000000\n",
      "mean   15733.50000     1.845556          1.749444     2.048889     1.945556\n",
      "std      519.75956     1.111130          0.993027     0.919705     0.936169\n",
      "min    14834.00000     0.000000          0.000000     0.000000     0.000000\n",
      "25%    15283.75000     1.000000          1.000000     2.000000     1.000000\n",
      "50%    15733.50000     2.000000          2.000000     2.000000     2.000000\n",
      "75%    16183.25000     3.000000          2.000000     3.000000     3.000000\n",
      "max    16633.00000     4.000000          4.000000     4.000000     4.000000\n",
      "Content_y\n",
      "Organization_y\n",
      "Word Choice_y\n",
      "Sentence Fluency_y\n",
      "Conventions_y\n",
      "Content_y\n",
      "Prompt Adherence_y\n",
      "Language_y\n",
      "Narrativity_y\n",
      "Content_y\n",
      "Prompt Adherence_y\n",
      "Language_y\n",
      "Narrativity_y\n",
      "Content_y\n",
      "Prompt Adherence_y\n",
      "Language_y\n",
      "Narrativity_y\n",
      "Content_y\n",
      "Organization_y\n",
      "Conventions_y\n",
      "Language_y\n",
      "Content_y\n",
      "Word Choice_y\n",
      "Sentence Fluency_y\n",
      "Organization_y\n",
      "Conventions_y\n",
      "Content_y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['essay_id', 'essay_set', 'essay', 'score', 'tokenize', 'sequence',\n",
       "       'pad_seq', 'Prompt Adherence', 'Narrativity', 'Language', 'Word Choice',\n",
       "       'Sentence Fluency', 'Organization', 'Conventions', 'Content'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = main\n",
    "prompt=[]\n",
    "for j in range(6):\n",
    "    i=j+1\n",
    "    print(i)\n",
    "    prompt.append(pd.read_csv('./Prompt-'+str(i)+\".csv\", sep=',', encoding = \"latin\"))\n",
    "    print(prompt[j].describe())\n",
    "#     print(prompt[j].columns)\n",
    "prompt[0][\"Essay ID\"]=prompt[0][\"EssayID\"]\n",
    "for i in [1,2]:\n",
    "    for c in prompt[i].columns:\n",
    "        if c!=\"EssayID\" and c!=\"Essay ID\":\n",
    "            prompt[i][c]=prompt[i][c]-1/5\n",
    "prompt.append(p7)\n",
    "prompt.append(p8)\n",
    "for j in range(8):\n",
    "    temp = pd.merge(new,prompt[j],left_on=\"essay_id\", right_on=\"Essay ID\", how=\"left\")\n",
    "    del temp[\"Essay ID\"]\n",
    "    for col in (c for c in new.columns if c in prompt[j].columns):\n",
    "        print(str(col + '_y'))\n",
    "        temp[col] = temp.apply(lambda x: x[col + '_x'] if x[col + '_x']==x[col + '_x'] else x[col + '_y'], axis=1)\n",
    "#         temp[col] = temp[str(col + '_y')]\n",
    "        del temp[col + '_x'], temp[col + '_y'], \n",
    "    new=temp\n",
    "del temp[\"EssayID\"]\n",
    "new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>score</th>\n",
       "      <th>Prompt Adherence</th>\n",
       "      <th>Narrativity</th>\n",
       "      <th>Language</th>\n",
       "      <th>Word Choice</th>\n",
       "      <th>Sentence Fluency</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Conventions</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12702.000000</td>\n",
       "      <td>12702.000000</td>\n",
       "      <td>12702.000000</td>\n",
       "      <td>7065.000000</td>\n",
       "      <td>7065.000000</td>\n",
       "      <td>8398.000000</td>\n",
       "      <td>4303.000000</td>\n",
       "      <td>4303.000000</td>\n",
       "      <td>5636.000000</td>\n",
       "      <td>5636.000000</td>\n",
       "      <td>12701.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10145.789088</td>\n",
       "      <td>4.129665</td>\n",
       "      <td>0.597187</td>\n",
       "      <td>1.596461</td>\n",
       "      <td>1.664119</td>\n",
       "      <td>1.757085</td>\n",
       "      <td>3.472926</td>\n",
       "      <td>3.577736</td>\n",
       "      <td>3.105926</td>\n",
       "      <td>3.152058</td>\n",
       "      <td>2.276356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6266.002399</td>\n",
       "      <td>2.123601</td>\n",
       "      <td>0.233829</td>\n",
       "      <td>1.030571</td>\n",
       "      <td>0.992466</td>\n",
       "      <td>0.964318</td>\n",
       "      <td>1.038384</td>\n",
       "      <td>0.989455</td>\n",
       "      <td>1.155502</td>\n",
       "      <td>1.092094</td>\n",
       "      <td>1.388479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4371.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9940.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15512.750000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21633.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           essay_id     essay_set         score  Prompt Adherence  \\\n",
       "count  12702.000000  12702.000000  12702.000000       7065.000000   \n",
       "mean   10145.789088      4.129665      0.597187          1.596461   \n",
       "std     6266.002399      2.123601      0.233829          1.030571   \n",
       "min        1.000000      1.000000      0.000000          0.000000   \n",
       "25%     4371.250000      2.000000      0.500000          1.000000   \n",
       "50%     9940.500000      4.000000      0.625000          2.000000   \n",
       "75%    15512.750000      6.000000      0.750000          2.000000   \n",
       "max    21633.000000      8.000000      1.000000          4.000000   \n",
       "\n",
       "       Narrativity     Language  Word Choice  Sentence Fluency  Organization  \\\n",
       "count  7065.000000  8398.000000  4303.000000       4303.000000   5636.000000   \n",
       "mean      1.664119     1.757085     3.472926          3.577736      3.105926   \n",
       "std       0.992466     0.964318     1.038384          0.989455      1.155502   \n",
       "min       0.000000     0.000000     1.000000          1.000000      0.000000   \n",
       "25%       1.000000     1.000000     3.000000          3.000000      2.000000   \n",
       "50%       2.000000     2.000000     4.000000          4.000000      3.000000   \n",
       "75%       2.000000     2.000000     4.000000          4.000000      4.000000   \n",
       "max       4.000000     4.000000     6.000000          6.000000      6.000000   \n",
       "\n",
       "       Conventions       Content  \n",
       "count  5636.000000  12701.000000  \n",
       "mean      3.152058      2.276356  \n",
       "std       1.092094      1.388479  \n",
       "min       0.000000      0.000000  \n",
       "25%       2.000000      1.000000  \n",
       "50%       3.000000      2.000000  \n",
       "75%       4.000000      3.000000  \n",
       "max       6.000000      6.000000  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['essay_id', 'essay_set', 'essay', 'score', 'tokenize', 'sequence',\n",
       "       'pad_seq', 'Prompt Adherence', 'Narrativity', 'Language', 'Word Choice',\n",
       "       'Sentence Fluency', 'Organization', 'Conventions', 'Content'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = new[new[\"Content\"]==new[\"Content\"]]\n",
    "new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = new\n",
    "del temp[\"essay_set\"], temp[\"essay\"], temp[\"tokenize\"], temp[\"sequence\"], temp[\"pad_seq\"]\n",
    "temp.to_csv(\"./essay_scores.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2.0\n",
       "1        2.0\n",
       "2        1.0\n",
       "3        3.0\n",
       "4        2.0\n",
       "5        1.0\n",
       "6        3.0\n",
       "7        4.0\n",
       "8        3.0\n",
       "9        1.0\n",
       "10       3.0\n",
       "11       2.0\n",
       "12       0.0\n",
       "13       0.0\n",
       "14       1.0\n",
       "15       4.0\n",
       "16       2.0\n",
       "17       1.0\n",
       "18      -1.0\n",
       "19       1.0\n",
       "20       3.0\n",
       "21      -1.0\n",
       "22       2.0\n",
       "23       2.0\n",
       "24       1.0\n",
       "25       1.0\n",
       "26      -1.0\n",
       "27       1.0\n",
       "28       2.0\n",
       "29       2.0\n",
       "        ... \n",
       "12672    2.0\n",
       "12673    2.0\n",
       "12674    2.0\n",
       "12675    1.0\n",
       "12676    1.0\n",
       "12677    3.0\n",
       "12678    2.0\n",
       "12679    2.0\n",
       "12680    2.0\n",
       "12681    1.0\n",
       "12682    2.0\n",
       "12683    3.0\n",
       "12684    2.0\n",
       "12685    2.0\n",
       "12686    2.0\n",
       "12687    2.0\n",
       "12688    2.0\n",
       "12689    1.0\n",
       "12690    2.0\n",
       "12691    2.0\n",
       "12692   -1.0\n",
       "12693    2.0\n",
       "12694    3.0\n",
       "12695    2.0\n",
       "12696    1.0\n",
       "12697    2.0\n",
       "12698    1.0\n",
       "12699    2.0\n",
       "12700    2.0\n",
       "12701    2.0\n",
       "Name: Content, Length: 12701, dtype: float64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[\"Content\"]-2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
