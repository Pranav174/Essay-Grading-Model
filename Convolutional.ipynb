{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models import Word2Vec\n",
    "import spacy; from spacy.lang.en import English; nlp = English()\n",
    "from metrics import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav_pro/SchoolSystem/models/essay/utils.py:6: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  data['illegible']=data.essay.str.contains('(\\?\\?\\?|illegible|not legible)')\n"
     ]
    }
   ],
   "source": [
    "data = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "w2vModel = Word2Vec.load('Essayw2v.model')\n",
    "vocab = set(w2vModel.wv.vocab)\n",
    "dic = w2vModel.wv\n",
    "w2v = dict(zip(w2vModel.wv.index2word, w2vModel.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2tokens(essay):\n",
    "    essay = basicClean(essay)\n",
    "    essay = replaceNER(essay)\n",
    "    essay = nlp(essay)\n",
    "#     essay = [token.text for token in essay if ((not token.is_punct) and (not token.is_stop))]\n",
    "    essay = [token.text for token in essay if (not token.is_punct)]\n",
    "    return essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12701/12701 [00:18<00:00, 696.30it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "data['tokenize'] = data['essay'].progress_apply(lambda x: convert2tokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[dear, local, newspaper, i, think, effects, co...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[dear, @caps, @caps, i, believe, that, using, ...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[dear, @caps, @caps, @caps, more, and, more, p...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[dear, local, newspaper, @caps, i, have, found...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[dear, @location, i, know, having, computers, ...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait5  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "3             NaN             NaN            NaN  ...            NaN   \n",
       "4             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater2_trait6  rater3_trait1  rater3_trait2  rater3_trait3  rater3_trait4  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait5  rater3_trait6  \\\n",
       "0            NaN            NaN   \n",
       "1            NaN            NaN   \n",
       "2            NaN            NaN   \n",
       "3            NaN            NaN   \n",
       "4            NaN            NaN   \n",
       "\n",
       "                                            tokenize  final_score  \n",
       "0  [dear, local, newspaper, i, think, effects, co...           40  \n",
       "1  [dear, @caps, @caps, i, believe, that, using, ...           45  \n",
       "2  [dear, @caps, @caps, @caps, more, and, more, p...           35  \n",
       "3  [dear, local, newspaper, @caps, i, have, found...           50  \n",
       "4  [dear, @location, i, know, having, computers, ...           40  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['final_score'] = data['domain1_score']\n",
    "mul = [5,10,20,20,15,15,2,1]\n",
    "data['final_score'] = data.apply(lambda row: row['final_score']*mul[row['essay_set']-1], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/keras_preprocessing/text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42443 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(nb_words=len(vocab))\n",
    "tokenizer.fit_on_texts(data['tokenize'])\n",
    "data['sequence'] = tokenizer.texts_to_sequences(data['tokenize'])\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    }
   ],
   "source": [
    "# MaxSequence = max([len(seq) for seq in data['sequence']])\n",
    "MaxSequence = 1200\n",
    "print(MaxSequence)\n",
    "tqdm.pandas()\n",
    "inputData = pad_sequences(data['sequence'], maxlen=MaxSequence)\n",
    "# data['padSequence'] = data['sequence'].progress_apply(lambda seq: pad_sequences([seq],maxlen=MaxSequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>final_score</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[dear, local, newspaper, i, think, effects, co...</td>\n",
       "      <td>40</td>\n",
       "      <td>[302, 485, 427, 7, 67, 524, 42, 20, 18, 21, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[dear, @caps, @caps, i, believe, that, using, ...</td>\n",
       "      <td>45</td>\n",
       "      <td>[302, 11, 11, 7, 176, 6, 312, 42, 60, 634, 105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[dear, @caps, @caps, @caps, more, and, more, p...</td>\n",
       "      <td>35</td>\n",
       "      <td>[302, 11, 11, 11, 76, 3, 76, 21, 122, 42, 35, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[dear, local, newspaper, @caps, i, have, found...</td>\n",
       "      <td>50</td>\n",
       "      <td>[302, 485, 427, 11, 7, 20, 250, 6, 73, 1267, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[dear, @location, i, know, having, computers, ...</td>\n",
       "      <td>40</td>\n",
       "      <td>[302, 127, 7, 90, 235, 42, 95, 4, 346, 288, 18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait6  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "3             NaN             NaN            NaN  ...            NaN   \n",
       "4             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater3_trait1  rater3_trait2  rater3_trait3  rater3_trait4  rater3_trait5  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait6                                           tokenize  \\\n",
       "0            NaN  [dear, local, newspaper, i, think, effects, co...   \n",
       "1            NaN  [dear, @caps, @caps, i, believe, that, using, ...   \n",
       "2            NaN  [dear, @caps, @caps, @caps, more, and, more, p...   \n",
       "3            NaN  [dear, local, newspaper, @caps, i, have, found...   \n",
       "4            NaN  [dear, @location, i, know, having, computers, ...   \n",
       "\n",
       "   final_score                                           sequence  \n",
       "0           40  [302, 485, 427, 7, 67, 524, 42, 20, 18, 21, 19...  \n",
       "1           45  [302, 11, 11, 7, 176, 6, 312, 42, 60, 634, 105...  \n",
       "2           35  [302, 11, 11, 11, 76, 3, 76, 21, 122, 42, 35, ...  \n",
       "3           50  [302, 485, 427, 11, 7, 20, 250, 6, 73, 1267, 1...  \n",
       "4           40  [302, 127, 7, 90, 235, 42, 95, 4, 346, 288, 18...  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    if word in vocab:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = dic[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(len(word_index) + 1,\n",
    "                            300,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MaxSequence,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7fb683ce6f60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def buildData(x,y):  \n",
    "    y = y/6\n",
    "    # split the data into a training set and a validation set\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    nb_validation_samples = int(0.1 * x.shape[0])\n",
    "\n",
    "    trainX = x[:-nb_validation_samples]\n",
    "    trainY = y[:-nb_validation_samples]\n",
    "    testX = x[-nb_validation_samples:]\n",
    "    testY = y[-nb_validation_samples:]\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.InputLayer((MaxSequence,), dtype='int32'))\n",
    "    model.add(embedding_layer)\n",
    "    model.add(layers.Conv1D(64, 5, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(35))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1,activation=\"linear\"))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                optimizer='adam',\n",
    "                metrics=['mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class IntervalEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=10):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict_proba(self.X_val, verbose=0)\n",
    "            score = kappa(self.y_val, y_pred,weights='quadratic')\n",
    "            print(\"interval evaluation - epoch: {:d} - score: {:.6f}\".format(epoch, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1200, 300)         12733200  \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 1196, 64)          96064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 34, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2176)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2176)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                139328    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 12,968,657\n",
      "Trainable params: 235,457\n",
      "Non-trainable params: 12,733,200\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "11424/11431 [============================>.] - ETA: 0s - loss: 3.0012 - mean_squared_error: 3.0012WARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "interval evaluation - epoch: 0 - score: 0.783897\n",
      "11431/11431 [==============================] - 31s 3ms/sample - loss: 3.0001 - mean_squared_error: 3.0001\n",
      "Epoch 2/10\n",
      "11424/11431 [============================>.] - ETA: 0s - loss: 2.1010 - mean_squared_error: 2.1010WARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "interval evaluation - epoch: 1 - score: 0.770039\n",
      "11431/11431 [==============================] - 30s 3ms/sample - loss: 2.1025 - mean_squared_error: 2.1025\n",
      "Epoch 3/10\n",
      "11424/11431 [============================>.] - ETA: 0s - loss: 1.9442 - mean_squared_error: 1.9442WARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "interval evaluation - epoch: 2 - score: 0.783133\n",
      "11431/11431 [==============================] - 30s 3ms/sample - loss: 1.9436 - mean_squared_error: 1.9436\n",
      "Epoch 4/10\n",
      "11424/11431 [============================>.] - ETA: 0s - loss: 1.8358 - mean_squared_error: 1.8358WARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "interval evaluation - epoch: 3 - score: 0.786322\n",
      "11431/11431 [==============================] - 30s 3ms/sample - loss: 1.8360 - mean_squared_error: 1.8360\n",
      "Epoch 5/10\n",
      "11424/11431 [============================>.] - ETA: 0s - loss: 1.7448 - mean_squared_error: 1.7448WARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "interval evaluation - epoch: 4 - score: 0.764094\n",
      "11431/11431 [==============================] - 30s 3ms/sample - loss: 1.7444 - mean_squared_error: 1.7444\n",
      "Epoch 6/10\n",
      "11424/11431 [============================>.] - ETA: 0s - loss: 1.6372 - mean_squared_error: 1.6372WARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "interval evaluation - epoch: 5 - score: 0.778910\n",
      "11431/11431 [==============================] - 30s 3ms/sample - loss: 1.6378 - mean_squared_error: 1.6378\n",
      "Epoch 7/10\n",
      "11424/11431 [============================>.] - ETA: 0s - loss: 1.6194 - mean_squared_error: 1.6194WARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "interval evaluation - epoch: 6 - score: 0.757527\n",
      "11431/11431 [==============================] - 30s 3ms/sample - loss: 1.6190 - mean_squared_error: 1.6190\n",
      "Epoch 8/10\n",
      "11424/11431 [============================>.] - ETA: 0s - loss: 1.5087 - mean_squared_error: 1.5087WARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "interval evaluation - epoch: 7 - score: 0.784515\n",
      "11431/11431 [==============================] - 30s 3ms/sample - loss: 1.5100 - mean_squared_error: 1.5100\n",
      "Epoch 9/10\n",
      "11424/11431 [============================>.] - ETA: 0s - loss: 1.4596 - mean_squared_error: 1.4596WARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "interval evaluation - epoch: 8 - score: 0.790385\n",
      "11431/11431 [==============================] - 33s 3ms/sample - loss: 1.4593 - mean_squared_error: 1.4593\n",
      "Epoch 10/10\n",
      "11424/11431 [============================>.] - ETA: 0s - loss: 1.3441 - mean_squared_error: 1.3441WARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "interval evaluation - epoch: 9 - score: 0.778940\n",
      "11431/11431 [==============================] - 35s 3ms/sample - loss: 1.3437 - mean_squared_error: 1.3437\n"
     ]
    }
   ],
   "source": [
    "trainX, trainY, testX, testY = buildData(inputData,np.array(data['final_score'].values.tolist()))\n",
    "model = build_model()\n",
    "model.summary()\n",
    "ival = IntervalEvaluation(validation_data=(testX, testY), interval=1)\n",
    "# history = model.fit(trainX, trainY, epochs=5,  callbacks=[ival], validation_split = 0.1, verbose=1)\n",
    "history = model.fit(trainX, trainY, epochs=10,  callbacks=[ival], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"EssayModelRNN.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
