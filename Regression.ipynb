{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from gensim.models import Word2Vec\n",
    "import spacy; from spacy.lang.en import English; nlp = English()\n",
    "from metrics import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav_pro/SchoolSystem/models/essay/utils.py:6: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  data['illegible']=data.essay.str.contains('(\\?\\?\\?|illegible|not legible)')\n"
     ]
    }
   ],
   "source": [
    "data = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "w2vModel = Word2Vec.load('Essayw2v.model')\n",
    "w2v = dict(zip(w2vModel.wv.index2word, w2vModel.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2vec(essay):\n",
    "    essay = basicClean(essay)\n",
    "    essay = replaceNER(essay)\n",
    "    essay = nlp(essay)\n",
    "#     essay = [token.text for token in essay if ((not token.is_punct) and (not token.is_stop))]\n",
    "    essay = [token.text for token in essay if (not token.is_punct)]\n",
    "\n",
    "    found = 0\n",
    "    embedding = np.zeros(300,dtype=\"float32\")\n",
    "    for word in essay:\n",
    "        if word in w2v:\n",
    "            found+=1\n",
    "            embedding += w2v[word]\n",
    "    if found>0:\n",
    "        embedding = np.divide(embedding,found)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12701/12701 [00:21<00:00, 598.24it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "data['emb'] = data['essay'].progress_apply(lambda x: convert2vec(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "      <th>emb</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.4341401, 0.3484266, -0.0023661503, -0.19002...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.455531, 0.36978564, 0.09307918, -0.08629133...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.39665243, 0.23396325, 0.020574056, -0.13223...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.42362538, 0.2999937, -0.06951589, -0.024058...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.35722917, 0.33758688, 0.26486138, -0.109733...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait5  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "3             NaN             NaN            NaN  ...            NaN   \n",
       "4             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater2_trait6  rater3_trait1  rater3_trait2  rater3_trait3  rater3_trait4  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait5  rater3_trait6  \\\n",
       "0            NaN            NaN   \n",
       "1            NaN            NaN   \n",
       "2            NaN            NaN   \n",
       "3            NaN            NaN   \n",
       "4            NaN            NaN   \n",
       "\n",
       "                                                 emb  final_score  \n",
       "0  [0.4341401, 0.3484266, -0.0023661503, -0.19002...           40  \n",
       "1  [0.455531, 0.36978564, 0.09307918, -0.08629133...           45  \n",
       "2  [0.39665243, 0.23396325, 0.020574056, -0.13223...           35  \n",
       "3  [0.42362538, 0.2999937, -0.06951589, -0.024058...           50  \n",
       "4  [0.35722917, 0.33758688, 0.26486138, -0.109733...           40  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['final_score'] = data['domain1_score']\n",
    "mul = [5,10,20,20,15,15,2,1]\n",
    "data['final_score'] = data.apply(lambda row: row['final_score']*mul[row['essay_set']-1], axis=1)\n",
    "# nndata.groupby('essay_set').describe()\n",
    "# data.describe()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def buildData():  \n",
    "    nndata = data.copy()\n",
    "#     nndata = nndata[(nndata['essay_set']!=7) & (nndata['essay_set']!=8)]\n",
    "    nndata = nndata[['emb', 'final_score']]\n",
    "    train_data = nndata.sample(frac=0.9)\n",
    "    test_data = nndata.drop(train_data.index)\n",
    "    train_labels = train_data.pop('final_score')\n",
    "    test_labels = test_data.pop('final_score')\n",
    "\n",
    "    trainX = np.zeros((len(train_data['emb']),300))\n",
    "    for i,emb in enumerate(train_data['emb']):\n",
    "        trainX[i]=emb\n",
    "    testX = np.zeros((len(test_data['emb']),300))\n",
    "    for i,emb in enumerate(test_data['emb']):\n",
    "        testX[i]=emb\n",
    "    trainY=np.array(train_labels)/60\n",
    "    testY=np.array(test_labels)/60\n",
    "#     np.shape(trainX)\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(64, activation=tf.nn.relu, input_shape=(300,)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation=tf.nn.relu),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1,activation=\"linear\")\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model.compile(loss='mean_squared_error',\n",
    "                optimizer='adam',\n",
    "                metrics=['mean_squared_error'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class IntervalEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=10):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict_proba(self.X_val, verbose=0)\n",
    "            score = kappa(self.y_val, y_pred,weights='quadratic')\n",
    "            print(\"interval evaluation - epoch: {:d} - score: {:.6f}\".format(epoch, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 64)                19264     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 27,713\n",
      "Trainable params: 27,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10287 samples, validate on 1144 samples\n",
      "Epoch 1/50\n",
      "10208/10287 [============================>.] - ETA: 0s - loss: 0.0786 - mean_squared_error: 0.0786interval evaluation - epoch: 0 - score: 0.106353\n",
      "10287/10287 [==============================] - 2s 175us/sample - loss: 0.0784 - mean_squared_error: 0.0784 - val_loss: 0.0443 - val_mean_squared_error: 0.0443\n",
      "Epoch 2/50\n",
      "10176/10287 [============================>.] - ETA: 0s - loss: 0.0482 - mean_squared_error: 0.0482interval evaluation - epoch: 1 - score: 0.268427\n",
      "10287/10287 [==============================] - 2s 170us/sample - loss: 0.0481 - mean_squared_error: 0.0481 - val_loss: 0.0390 - val_mean_squared_error: 0.0390\n",
      "Epoch 3/50\n",
      "10272/10287 [============================>.] - ETA: 0s - loss: 0.0440 - mean_squared_error: 0.0440interval evaluation - epoch: 2 - score: 0.376115\n",
      "10287/10287 [==============================] - 2s 160us/sample - loss: 0.0440 - mean_squared_error: 0.0440 - val_loss: 0.0353 - val_mean_squared_error: 0.0353\n",
      "Epoch 4/50\n",
      " 9664/10287 [===========================>..] - ETA: 0s - loss: 0.0403 - mean_squared_error: 0.0403interval evaluation - epoch: 3 - score: 0.312565\n",
      "10287/10287 [==============================] - 1s 93us/sample - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.0344 - val_mean_squared_error: 0.0344\n",
      "Epoch 5/50\n",
      " 9760/10287 [===========================>..] - ETA: 0s - loss: 0.0382 - mean_squared_error: 0.0382interval evaluation - epoch: 4 - score: 0.395427\n",
      "10287/10287 [==============================] - 1s 92us/sample - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.0326 - val_mean_squared_error: 0.0326\n",
      "Epoch 6/50\n",
      " 9760/10287 [===========================>..] - ETA: 0s - loss: 0.0359 - mean_squared_error: 0.0359interval evaluation - epoch: 5 - score: 0.388405\n",
      "10287/10287 [==============================] - 1s 92us/sample - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0323 - val_mean_squared_error: 0.0323\n",
      "Epoch 7/50\n",
      "10048/10287 [============================>.] - ETA: 0s - loss: 0.0339 - mean_squared_error: 0.0339interval evaluation - epoch: 6 - score: 0.413119\n",
      "10287/10287 [==============================] - 1s 97us/sample - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0315 - val_mean_squared_error: 0.0315\n",
      "Epoch 8/50\n",
      " 9952/10287 [============================>.] - ETA: 0s - loss: 0.0330 - mean_squared_error: 0.0330interval evaluation - epoch: 7 - score: 0.370730\n",
      "10287/10287 [==============================] - 1s 96us/sample - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0320 - val_mean_squared_error: 0.0320\n",
      "Epoch 9/50\n",
      " 9792/10287 [===========================>..] - ETA: 0s - loss: 0.0320 - mean_squared_error: 0.0320interval evaluation - epoch: 8 - score: 0.411553\n",
      "10287/10287 [==============================] - 1s 120us/sample - loss: 0.0319 - mean_squared_error: 0.0319 - val_loss: 0.0314 - val_mean_squared_error: 0.0314\n",
      "Epoch 10/50\n",
      "10080/10287 [============================>.] - ETA: 0s - loss: 0.0317 - mean_squared_error: 0.0317interval evaluation - epoch: 9 - score: 0.408939\n",
      "10287/10287 [==============================] - 1s 129us/sample - loss: 0.0317 - mean_squared_error: 0.0317 - val_loss: 0.0309 - val_mean_squared_error: 0.0309\n",
      "Epoch 11/50\n",
      "10176/10287 [============================>.] - ETA: 0s - loss: 0.0305 - mean_squared_error: 0.0305interval evaluation - epoch: 10 - score: 0.373996\n",
      "10287/10287 [==============================] - 1s 127us/sample - loss: 0.0306 - mean_squared_error: 0.0306 - val_loss: 0.0314 - val_mean_squared_error: 0.0314\n",
      "Epoch 12/50\n",
      "10016/10287 [============================>.] - ETA: 0s - loss: 0.0306 - mean_squared_error: 0.0306interval evaluation - epoch: 11 - score: 0.417836\n",
      "10287/10287 [==============================] - 1s 125us/sample - loss: 0.0305 - mean_squared_error: 0.0305 - val_loss: 0.0309 - val_mean_squared_error: 0.0309\n",
      "Epoch 13/50\n",
      "10112/10287 [============================>.] - ETA: 0s - loss: 0.0299 - mean_squared_error: 0.0299interval evaluation - epoch: 12 - score: 0.346487\n",
      "10287/10287 [==============================] - 1s 99us/sample - loss: 0.0299 - mean_squared_error: 0.0299 - val_loss: 0.0306 - val_mean_squared_error: 0.0306\n",
      "Epoch 14/50\n",
      " 9728/10287 [===========================>..] - ETA: 0s - loss: 0.0288 - mean_squared_error: 0.0288interval evaluation - epoch: 13 - score: 0.401155\n",
      "10287/10287 [==============================] - 1s 98us/sample - loss: 0.0290 - mean_squared_error: 0.0290 - val_loss: 0.0319 - val_mean_squared_error: 0.0319\n",
      "Epoch 15/50\n",
      " 9856/10287 [===========================>..] - ETA: 0s - loss: 0.0287 - mean_squared_error: 0.0287interval evaluation - epoch: 14 - score: 0.383272\n",
      "10287/10287 [==============================] - 1s 125us/sample - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.0316 - val_mean_squared_error: 0.0316\n",
      "Epoch 16/50\n",
      " 9888/10287 [===========================>..] - ETA: 0s - loss: 0.0289 - mean_squared_error: 0.0289WARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "interval evaluation - epoch: 15 - score: 0.396358\n",
      "10287/10287 [==============================] - 1s 145us/sample - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.0294 - val_mean_squared_error: 0.0294\n",
      "Epoch 17/50\n",
      " 9984/10287 [============================>.] - ETA: 0s - loss: 0.0287 - mean_squared_error: 0.0287interval evaluation - epoch: 16 - score: 0.387565\n",
      "10287/10287 [==============================] - 2s 146us/sample - loss: 0.0286 - mean_squared_error: 0.0286 - val_loss: 0.0299 - val_mean_squared_error: 0.0299\n",
      "Epoch 18/50\n",
      "10144/10287 [============================>.] - ETA: 0s - loss: 0.0279 - mean_squared_error: 0.0279interval evaluation - epoch: 17 - score: 0.352630\n",
      "10287/10287 [==============================] - 2s 146us/sample - loss: 0.0279 - mean_squared_error: 0.0279 - val_loss: 0.0313 - val_mean_squared_error: 0.0313\n",
      "Epoch 19/50\n",
      "10272/10287 [============================>.] - ETA: 0s - loss: 0.0278 - mean_squared_error: 0.0278interval evaluation - epoch: 18 - score: 0.390169\n",
      "10287/10287 [==============================] - 1s 138us/sample - loss: 0.0278 - mean_squared_error: 0.0278 - val_loss: 0.0296 - val_mean_squared_error: 0.0296\n",
      "Epoch 20/50\n",
      "10240/10287 [============================>.] - ETA: 0s - loss: 0.0273 - mean_squared_error: 0.0273interval evaluation - epoch: 19 - score: 0.397431\n",
      "10287/10287 [==============================] - 1s 141us/sample - loss: 0.0273 - mean_squared_error: 0.0273 - val_loss: 0.0298 - val_mean_squared_error: 0.0298\n",
      "Epoch 21/50\n",
      " 9920/10287 [===========================>..] - ETA: 0s - loss: 0.0270 - mean_squared_error: 0.0270interval evaluation - epoch: 20 - score: 0.349437\n",
      "10287/10287 [==============================] - 1s 145us/sample - loss: 0.0271 - mean_squared_error: 0.0271 - val_loss: 0.0304 - val_mean_squared_error: 0.0304\n",
      "Epoch 22/50\n",
      "10208/10287 [============================>.] - ETA: 0s - loss: 0.0267 - mean_squared_error: 0.0267interval evaluation - epoch: 21 - score: 0.368590\n",
      "10287/10287 [==============================] - 1s 145us/sample - loss: 0.0266 - mean_squared_error: 0.0266 - val_loss: 0.0295 - val_mean_squared_error: 0.0295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "10144/10287 [============================>.] - ETA: 0s - loss: 0.0266 - mean_squared_error: 0.0266interval evaluation - epoch: 22 - score: 0.368020\n",
      "10287/10287 [==============================] - 1s 145us/sample - loss: 0.0266 - mean_squared_error: 0.0266 - val_loss: 0.0300 - val_mean_squared_error: 0.0300\n",
      "Epoch 24/50\n",
      "10080/10287 [============================>.] - ETA: 0s - loss: 0.0264 - mean_squared_error: 0.0264interval evaluation - epoch: 23 - score: 0.351820\n",
      "10287/10287 [==============================] - 1s 138us/sample - loss: 0.0264 - mean_squared_error: 0.0264 - val_loss: 0.0298 - val_mean_squared_error: 0.0298\n",
      "Epoch 25/50\n",
      "10112/10287 [============================>.] - ETA: 0s - loss: 0.0264 - mean_squared_error: 0.0264interval evaluation - epoch: 24 - score: 0.390938\n",
      "10287/10287 [==============================] - 1s 140us/sample - loss: 0.0264 - mean_squared_error: 0.0264 - val_loss: 0.0291 - val_mean_squared_error: 0.0291\n",
      "Epoch 26/50\n",
      "10176/10287 [============================>.] - ETA: 0s - loss: 0.0262 - mean_squared_error: 0.0262interval evaluation - epoch: 25 - score: 0.361847\n",
      "10287/10287 [==============================] - 1s 135us/sample - loss: 0.0262 - mean_squared_error: 0.0262 - val_loss: 0.0295 - val_mean_squared_error: 0.0295\n",
      "Epoch 27/50\n",
      " 9888/10287 [===========================>..] - ETA: 0s - loss: 0.0258 - mean_squared_error: 0.0258interval evaluation - epoch: 26 - score: 0.367156\n",
      "10287/10287 [==============================] - 1s 137us/sample - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0300 - val_mean_squared_error: 0.0300\n",
      "Epoch 28/50\n",
      " 9984/10287 [============================>.] - ETA: 0s - loss: 0.0257 - mean_squared_error: 0.0257interval evaluation - epoch: 27 - score: 0.366598\n",
      "10287/10287 [==============================] - 1s 137us/sample - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0292 - val_mean_squared_error: 0.0292\n",
      "Epoch 29/50\n",
      " 9856/10287 [===========================>..] - ETA: 0s - loss: 0.0257 - mean_squared_error: 0.0257interval evaluation - epoch: 28 - score: 0.369904\n",
      "10287/10287 [==============================] - 1s 136us/sample - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.0294 - val_mean_squared_error: 0.0294\n",
      "Epoch 30/50\n",
      "10112/10287 [============================>.] - ETA: 0s - loss: 0.0255 - mean_squared_error: 0.0255interval evaluation - epoch: 29 - score: 0.370791\n",
      "10287/10287 [==============================] - 2s 157us/sample - loss: 0.0255 - mean_squared_error: 0.0255 - val_loss: 0.0296 - val_mean_squared_error: 0.0296\n",
      "Epoch 31/50\n",
      "10048/10287 [============================>.] - ETA: 0s - loss: 0.0252 - mean_squared_error: 0.0252interval evaluation - epoch: 30 - score: 0.369289\n",
      "10287/10287 [==============================] - 2s 159us/sample - loss: 0.0252 - mean_squared_error: 0.0252 - val_loss: 0.0298 - val_mean_squared_error: 0.0298\n",
      "Epoch 32/50\n",
      " 9952/10287 [============================>.] - ETA: 0s - loss: 0.0250 - mean_squared_error: 0.0250interval evaluation - epoch: 31 - score: 0.353592\n",
      "10287/10287 [==============================] - 1s 130us/sample - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.0292 - val_mean_squared_error: 0.0292\n",
      "Epoch 33/50\n",
      " 9888/10287 [===========================>..] - ETA: 0s - loss: 0.0255 - mean_squared_error: 0.0255interval evaluation - epoch: 32 - score: 0.432917\n",
      "10287/10287 [==============================] - 1s 135us/sample - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.0285 - val_mean_squared_error: 0.0285\n",
      "Epoch 34/50\n",
      "10208/10287 [============================>.] - ETA: 0s - loss: 0.0246 - mean_squared_error: 0.0246interval evaluation - epoch: 33 - score: 0.367174\n",
      "10287/10287 [==============================] - 2s 167us/sample - loss: 0.0246 - mean_squared_error: 0.0246 - val_loss: 0.0287 - val_mean_squared_error: 0.0287\n",
      "Epoch 35/50\n",
      "10208/10287 [============================>.] - ETA: 0s - loss: 0.0243 - mean_squared_error: 0.0243interval evaluation - epoch: 34 - score: 0.382979\n",
      "10287/10287 [==============================] - 1s 140us/sample - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.0286 - val_mean_squared_error: 0.0286\n",
      "Epoch 36/50\n",
      "10240/10287 [============================>.] - ETA: 0s - loss: 0.0245 - mean_squared_error: 0.0245interval evaluation - epoch: 35 - score: 0.346076\n",
      "10287/10287 [==============================] - 1s 99us/sample - loss: 0.0245 - mean_squared_error: 0.0245 - val_loss: 0.0297 - val_mean_squared_error: 0.0297\n",
      "Epoch 37/50\n",
      "10272/10287 [============================>.] - ETA: 0s - loss: 0.0245 - mean_squared_error: 0.0245interval evaluation - epoch: 36 - score: 0.386133\n",
      "10287/10287 [==============================] - 1s 98us/sample - loss: 0.0245 - mean_squared_error: 0.0245 - val_loss: 0.0294 - val_mean_squared_error: 0.0294\n",
      "Epoch 38/50\n",
      " 9856/10287 [===========================>..] - ETA: 0s - loss: 0.0244 - mean_squared_error: 0.0244interval evaluation - epoch: 37 - score: 0.413139\n",
      "10287/10287 [==============================] - 1s 102us/sample - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0282 - val_mean_squared_error: 0.0282\n",
      "Epoch 39/50\n",
      "10016/10287 [============================>.] - ETA: 0s - loss: 0.0243 - mean_squared_error: 0.0243interval evaluation - epoch: 38 - score: 0.390938\n",
      "10287/10287 [==============================] - 1s 95us/sample - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0284 - val_mean_squared_error: 0.0284\n",
      "Epoch 40/50\n",
      "10048/10287 [============================>.] - ETA: 0s - loss: 0.0237 - mean_squared_error: 0.0237interval evaluation - epoch: 39 - score: 0.355940\n",
      "10287/10287 [==============================] - 1s 117us/sample - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0288 - val_mean_squared_error: 0.0288\n",
      "Epoch 41/50\n",
      " 9728/10287 [===========================>..] - ETA: 0s - loss: 0.0240 - mean_squared_error: 0.0240interval evaluation - epoch: 40 - score: 0.382802\n",
      "10287/10287 [==============================] - 1s 92us/sample - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0289 - val_mean_squared_error: 0.0289\n",
      "Epoch 42/50\n",
      "10272/10287 [============================>.] - ETA: 0s - loss: 0.0239 - mean_squared_error: 0.0239interval evaluation - epoch: 41 - score: 0.429774\n",
      "10287/10287 [==============================] - 1s 104us/sample - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.0281 - val_mean_squared_error: 0.0281\n",
      "Epoch 43/50\n",
      "10112/10287 [============================>.] - ETA: 0s - loss: 0.0236 - mean_squared_error: 0.0236interval evaluation - epoch: 42 - score: 0.417879\n",
      "10287/10287 [==============================] - 1s 101us/sample - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0285 - val_mean_squared_error: 0.0285\n",
      "Epoch 44/50\n",
      " 9952/10287 [============================>.] - ETA: 0s - loss: 0.0228 - mean_squared_error: 0.0228interval evaluation - epoch: 43 - score: 0.361108\n",
      "10287/10287 [==============================] - 1s 105us/sample - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0287 - val_mean_squared_error: 0.0287\n",
      "Epoch 45/50\n",
      " 9888/10287 [===========================>..] - ETA: 0s - loss: 0.0239 - mean_squared_error: 0.0239interval evaluation - epoch: 44 - score: 0.391910\n",
      "10287/10287 [==============================] - 1s 92us/sample - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0291 - val_mean_squared_error: 0.0291\n",
      "Epoch 46/50\n",
      "10240/10287 [============================>.] - ETA: 0s - loss: 0.0232 - mean_squared_error: 0.0232interval evaluation - epoch: 45 - score: 0.428152\n",
      "10287/10287 [==============================] - 1s 120us/sample - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0274 - val_mean_squared_error: 0.0274\n",
      "Epoch 47/50\n",
      "10240/10287 [============================>.] - ETA: 0s - loss: 0.0234 - mean_squared_error: 0.0234interval evaluation - epoch: 46 - score: 0.435338\n",
      "10287/10287 [==============================] - 1s 112us/sample - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0280 - val_mean_squared_error: 0.0280\n",
      "Epoch 48/50\n",
      "10176/10287 [============================>.] - ETA: 0s - loss: 0.0231 - mean_squared_error: 0.0231interval evaluation - epoch: 47 - score: 0.376580\n",
      "10287/10287 [==============================] - 1s 137us/sample - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0282 - val_mean_squared_error: 0.0282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "10112/10287 [============================>.] - ETA: 0s - loss: 0.0226 - mean_squared_error: 0.0226interval evaluation - epoch: 48 - score: 0.428152\n",
      "10287/10287 [==============================] - 1s 95us/sample - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.0276 - val_mean_squared_error: 0.0276\n",
      "Epoch 50/50\n",
      "10176/10287 [============================>.] - ETA: 0s - loss: 0.0225 - mean_squared_error: 0.0225interval evaluation - epoch: 49 - score: 0.402556\n",
      "10287/10287 [==============================] - 1s 104us/sample - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0271 - val_mean_squared_error: 0.0271\n"
     ]
    }
   ],
   "source": [
    "trainX, trainY, testX, testY = buildData()\n",
    "model = build_model()\n",
    "model.summary()\n",
    "#sess = tf.Session()\n",
    "ival = IntervalEvaluation(validation_data=(testX, testY), interval=1)\n",
    "history = model.fit(trainX, trainY, epochs=50,  callbacks=[ival], validation_split = 0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  hist['epoch'] = history.epoch  \n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Square Error [$MSE^2$]')\n",
    "  plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
    "           label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
    "           label = 'Val Error')\n",
    "  plt.ylim([0,0.06])\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"EssayModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = model.predict(trainX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.66666667, 0.66666667, ..., 0.16666667, 0.73333333,\n",
       "       0.53333333])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11045\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for x in trainY:\n",
    "    if(x>0.1):\n",
    "        c+=1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11430\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for x in ans:\n",
    "    if(x>0.1):\n",
    "        c+=1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
