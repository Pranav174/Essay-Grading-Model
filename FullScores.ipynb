{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav_pro/SchoolSystem/models/essay/utils.py:6: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  data['illegible']=data.essay.str.contains('(\\?\\?\\?|illegible|not legible)')\n"
     ]
    }
   ],
   "source": [
    "data = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = data[[\"essay_id\", \"essay_set\", \"essay\", \"domain2_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "main[\"score\"] = data['domain1_score']\n",
    "main.score=main.apply(lambda x: x['score'] if x['essay_set']!=2 else x['score']+x['domain2_score'], axis=1)\n",
    "main.score=main.apply(lambda x: x['score'] if x['essay_set']!=2 and x['essay_set']!=1 else x['score']-2, axis=1)\n",
    "main = main.drop([\"domain2_score\"], axis=1)\n",
    "mul = np.array([12,15,40,40,30,30,4,2])/120\n",
    "main['score'] = main.apply(lambda row: row['score']*mul[row['essay_set']-1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/pranav_pro/SchoolSystem/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "p7 = data.loc[data['essay_set']==7]\n",
    "p8 = data.loc[data['essay_set']==8]\n",
    "p7[\"Essay ID\"] = p7['essay_id']\n",
    "p8[\"Essay ID\"] = p8['essay_id']\n",
    "p7['Content'] = p7['rater1_trait1']/3\n",
    "p7['Organization'] = p7['rater1_trait2']/3\n",
    "p7['Language'] = p7['rater1_trait3']/3\n",
    "p7['Conventions'] = p7['rater1_trait4']/3\n",
    "p7 = p7[[\"Essay ID\", \"Content\", \"Organization\", \"Language\", \"Conventions\"]]\n",
    "p8['Content'] = (p8['rater1_trait1']-1)/5\n",
    "p8['Organization'] = (p8['rater1_trait2']-1)/5\n",
    "p8['Word Choice'] = (p8['rater1_trait4']-1)/5\n",
    "p8['Sentence Fluency'] = (p8['rater1_trait5']-1)/5\n",
    "p8['Conventions'] = (p8['rater1_trait6']-1)/5\n",
    "p8 = p8[[\"Essay ID\", \"Content\", \"Organization\", \"Word Choice\", \"Sentence Fluency\", 'Conventions']]\n",
    "# data['Organization'] = data['rater1_trait1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "           EssayID      Content  Organization  Word Choice  Sentence Fluency  \\\n",
      "count  1783.000000  1783.000000   1783.000000  1783.000000       1783.000000   \n",
      "mean    894.310151     3.846887      3.737521     3.679192          3.762759   \n",
      "std     516.143993     0.991320      0.950858     0.966469          0.968832   \n",
      "min       1.000000     1.000000      1.000000     1.000000          1.000000   \n",
      "25%     448.500000     3.000000      3.000000     3.000000          3.000000   \n",
      "50%     894.000000     4.000000      4.000000     4.000000          4.000000   \n",
      "75%    1341.500000     4.000000      4.000000     4.000000          4.000000   \n",
      "max    1787.000000     6.000000      6.000000     6.000000          6.000000   \n",
      "\n",
      "       Conventions  \n",
      "count  1783.000000  \n",
      "mean      3.737521  \n",
      "std       0.948494  \n",
      "min       1.000000  \n",
      "25%       3.000000  \n",
      "50%       4.000000  \n",
      "75%       4.000000  \n",
      "max       6.000000  \n",
      "2\n",
      "          Essay ID      Content  Organization  Word Choice  Sentence Fluency  \\\n",
      "count  1800.000000  1800.000000   1800.000000  1800.000000       1800.000000   \n",
      "mean   3877.494444     3.220000      3.043333     3.111667          3.332778   \n",
      "std     519.754400     1.165771      1.128887     1.120965          1.050071   \n",
      "min    2978.000000     1.000000      1.000000     1.000000          1.000000   \n",
      "25%    3427.750000     2.000000      2.000000     2.000000          3.000000   \n",
      "50%    3877.500000     3.000000      3.000000     3.000000          3.000000   \n",
      "75%    4327.250000     4.000000      4.000000     4.000000          4.000000   \n",
      "max    4777.000000     6.000000      6.000000     6.000000          6.000000   \n",
      "\n",
      "       Conventions  \n",
      "count  1800.000000  \n",
      "mean      3.132778  \n",
      "std       1.085368  \n",
      "min       1.000000  \n",
      "25%       2.000000  \n",
      "50%       3.000000  \n",
      "75%       4.000000  \n",
      "max       6.000000  \n",
      "3\n",
      "          Essay ID      Content  Prompt Adherence     Language  Narrativity\n",
      "count  1726.000000  1726.000000       1726.000000  1726.000000  1726.000000\n",
      "mean   6843.016222     1.434531          1.478563     1.472190     1.440904\n",
      "std     499.809908     0.838944          0.876325     0.846533     0.893608\n",
      "min    5978.000000     0.000000          0.000000     0.000000     0.000000\n",
      "25%    6410.250000     1.000000          1.000000     1.000000     1.000000\n",
      "50%    6842.500000     2.000000          2.000000     2.000000     1.000000\n",
      "75%    7275.750000     2.000000          2.000000     2.000000     2.000000\n",
      "max    7708.000000     3.000000          3.000000     3.000000     3.000000\n",
      "4\n",
      "           Essay ID      Content  Prompt Adherence     Language  Narrativity\n",
      "count   1772.000000  1772.000000       1772.000000  1772.000000  1772.000000\n",
      "mean    9751.358916     1.108916          1.099887     1.059819     1.209932\n",
      "std      513.750550     0.970479          0.943736     0.876205     0.990612\n",
      "min     8863.000000     0.000000          0.000000     0.000000     0.000000\n",
      "25%     9306.750000     0.000000          0.000000     0.000000     0.000000\n",
      "50%     9751.500000     1.000000          1.000000     1.000000     1.000000\n",
      "75%    10196.250000     2.000000          2.000000     2.000000     2.000000\n",
      "max    10642.000000     3.000000          3.000000     3.000000     3.000000\n",
      "5\n",
      "           Essay ID      Content  Prompt Adherence     Language  Narrativity\n",
      "count   1805.000000  1805.000000       1805.000000  1805.000000  1805.000000\n",
      "mean   12729.000000     1.884211          2.034349     2.236565     2.029363\n",
      "std      521.202936     1.001883          1.056043     0.938812     0.903137\n",
      "min    11827.000000     0.000000          0.000000     0.000000     0.000000\n",
      "25%    12278.000000     1.000000          1.000000     2.000000     2.000000\n",
      "50%    12729.000000     2.000000          2.000000     2.000000     2.000000\n",
      "75%    13180.000000     3.000000          3.000000     3.000000     3.000000\n",
      "max    13631.000000     4.000000          4.000000     4.000000     4.000000\n",
      "6\n",
      "          Essay ID      Content  Prompt Adherence     Language  Narrativity\n",
      "count   1800.00000  1800.000000       1800.000000  1800.000000  1800.000000\n",
      "mean   15733.50000     1.845556          1.749444     2.048889     1.945556\n",
      "std      519.75956     1.111130          0.993027     0.919705     0.936169\n",
      "min    14834.00000     0.000000          0.000000     0.000000     0.000000\n",
      "25%    15283.75000     1.000000          1.000000     2.000000     1.000000\n",
      "50%    15733.50000     2.000000          2.000000     2.000000     2.000000\n",
      "75%    16183.25000     3.000000          2.000000     3.000000     3.000000\n",
      "max    16633.00000     4.000000          4.000000     4.000000     4.000000\n",
      "1\n",
      "           EssayID      Content  Organization  Word Choice  Sentence Fluency  \\\n",
      "count  1783.000000  1783.000000   1783.000000  1783.000000       1783.000000   \n",
      "mean    894.310151     0.569377      0.547504     0.535838          0.552552   \n",
      "std     516.143993     0.198264      0.190172     0.193294          0.193766   \n",
      "min       1.000000     0.000000      0.000000     0.000000          0.000000   \n",
      "25%     448.500000     0.400000      0.400000     0.400000          0.400000   \n",
      "50%     894.000000     0.600000      0.600000     0.600000          0.600000   \n",
      "75%    1341.500000     0.600000      0.600000     0.600000          0.600000   \n",
      "max    1787.000000     1.000000      1.000000     1.000000          1.000000   \n",
      "\n",
      "       Conventions     Essay ID  \n",
      "count  1783.000000  1783.000000  \n",
      "mean      0.547504   894.310151  \n",
      "std       0.189699   516.143993  \n",
      "min       0.000000     1.000000  \n",
      "25%       0.400000   448.500000  \n",
      "50%       0.600000   894.000000  \n",
      "75%       0.600000  1341.500000  \n",
      "max       1.000000  1787.000000  \n",
      "2\n",
      "          Essay ID      Content  Organization  Word Choice  Sentence Fluency  \\\n",
      "count  1800.000000  1800.000000   1800.000000  1800.000000       1800.000000   \n",
      "mean   3877.494444     0.444000      0.408667     0.422333          0.466556   \n",
      "std     519.754400     0.233154      0.225777     0.224193          0.210014   \n",
      "min    2978.000000     0.000000      0.000000     0.000000          0.000000   \n",
      "25%    3427.750000     0.200000      0.200000     0.200000          0.400000   \n",
      "50%    3877.500000     0.400000      0.400000     0.400000          0.400000   \n",
      "75%    4327.250000     0.600000      0.600000     0.600000          0.600000   \n",
      "max    4777.000000     1.000000      1.000000     1.000000          1.000000   \n",
      "\n",
      "       Conventions  \n",
      "count  1800.000000  \n",
      "mean      0.426556  \n",
      "std       0.217074  \n",
      "min       0.000000  \n",
      "25%       0.200000  \n",
      "50%       0.400000  \n",
      "75%       0.600000  \n",
      "max       1.000000  \n",
      "3\n",
      "          Essay ID      Content  Prompt Adherence     Language  Narrativity\n",
      "count  1726.000000  1726.000000       1726.000000  1726.000000  1726.000000\n",
      "mean   6843.016222     0.478177          0.492854     0.490730     0.480301\n",
      "std     499.809908     0.279648          0.292108     0.282178     0.297869\n",
      "min    5978.000000     0.000000          0.000000     0.000000     0.000000\n",
      "25%    6410.250000     0.333333          0.333333     0.333333     0.333333\n",
      "50%    6842.500000     0.666667          0.666667     0.666667     0.333333\n",
      "75%    7275.750000     0.666667          0.666667     0.666667     0.666667\n",
      "max    7708.000000     1.000000          1.000000     1.000000     1.000000\n",
      "4\n",
      "           Essay ID      Content  Prompt Adherence     Language  Narrativity\n",
      "count   1772.000000  1772.000000       1772.000000  1772.000000  1772.000000\n",
      "mean    9751.358916     0.369639          0.366629     0.353273     0.403311\n",
      "std      513.750550     0.323493          0.314579     0.292068     0.330204\n",
      "min     8863.000000     0.000000          0.000000     0.000000     0.000000\n",
      "25%     9306.750000     0.000000          0.000000     0.000000     0.000000\n",
      "50%     9751.500000     0.333333          0.333333     0.333333     0.333333\n",
      "75%    10196.250000     0.666667          0.666667     0.666667     0.666667\n",
      "max    10642.000000     1.000000          1.000000     1.000000     1.000000\n",
      "5\n",
      "           Essay ID      Content  Prompt Adherence     Language  Narrativity\n",
      "count   1805.000000  1805.000000       1805.000000  1805.000000  1805.000000\n",
      "mean   12729.000000     0.471053          0.508587     0.559141     0.507341\n",
      "std      521.202936     0.250471          0.264011     0.234703     0.225784\n",
      "min    11827.000000     0.000000          0.000000     0.000000     0.000000\n",
      "25%    12278.000000     0.250000          0.250000     0.500000     0.500000\n",
      "50%    12729.000000     0.500000          0.500000     0.500000     0.500000\n",
      "75%    13180.000000     0.750000          0.750000     0.750000     0.750000\n",
      "max    13631.000000     1.000000          1.000000     1.000000     1.000000\n",
      "6\n",
      "          Essay ID      Content  Prompt Adherence     Language  Narrativity\n",
      "count   1800.00000  1800.000000       1800.000000  1800.000000  1800.000000\n",
      "mean   15733.50000     0.461389          0.437361     0.512222     0.486389\n",
      "std      519.75956     0.277783          0.248257     0.229926     0.234042\n",
      "min    14834.00000     0.000000          0.000000     0.000000     0.000000\n",
      "25%    15283.75000     0.250000          0.250000     0.500000     0.250000\n",
      "50%    15733.50000     0.500000          0.500000     0.500000     0.500000\n",
      "75%    16183.25000     0.750000          0.500000     0.750000     0.750000\n",
      "max    16633.00000     1.000000          1.000000     1.000000     1.000000\n",
      "7\n",
      "           Essay ID      Content  Organization     Language  Conventions\n",
      "count   1333.000000  1333.000000   1333.000000  1333.000000  1333.000000\n",
      "mean   18696.284321     0.607652      0.671668     0.662416     0.724181\n",
      "std      499.403100     0.285949      0.241246     0.205201     0.230027\n",
      "min    17834.000000     0.000000      0.000000     0.000000     0.000000\n",
      "25%    18259.000000     0.333333      0.666667     0.666667     0.666667\n",
      "50%    18705.000000     0.666667      0.666667     0.666667     0.666667\n",
      "75%    19124.000000     0.666667      1.000000     0.666667     1.000000\n",
      "max    19563.000000     1.000000      1.000000     1.000000     1.000000\n",
      "8\n",
      "           Essay ID     Content  Organization  Word Choice  Sentence Fluency  \\\n",
      "count    722.000000  722.000000    722.000000   722.000000        722.000000   \n",
      "mean   21168.975069    0.552355      0.543767     0.573130          0.546537   \n",
      "std      262.783588    0.142306      0.139331     0.127706          0.143545   \n",
      "min    20716.000000    0.000000      0.000000     0.000000          0.000000   \n",
      "25%    20940.500000    0.400000      0.400000     0.600000          0.400000   \n",
      "50%    21163.500000    0.600000      0.600000     0.600000          0.600000   \n",
      "75%    21396.250000    0.600000      0.600000     0.600000          0.600000   \n",
      "max    21633.000000    1.000000      1.000000     1.000000          1.000000   \n",
      "\n",
      "       Conventions  \n",
      "count   722.000000  \n",
      "mean      0.513019  \n",
      "std       0.140030  \n",
      "min       0.000000  \n",
      "25%       0.400000  \n",
      "50%       0.600000  \n",
      "75%       0.600000  \n",
      "max       1.000000  \n",
      "Content_y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organization_y\n",
      "Word Choice_y\n",
      "Sentence Fluency_y\n",
      "Conventions_y\n",
      "Content_y\n",
      "Prompt Adherence_y\n",
      "Language_y\n",
      "Narrativity_y\n",
      "Content_y\n",
      "Prompt Adherence_y\n",
      "Language_y\n",
      "Narrativity_y\n",
      "Content_y\n",
      "Prompt Adherence_y\n",
      "Language_y\n",
      "Narrativity_y\n",
      "Content_y\n",
      "Organization_y\n",
      "Conventions_y\n",
      "Language_y\n",
      "Content_y\n",
      "Word Choice_y\n",
      "Sentence Fluency_y\n",
      "Organization_y\n",
      "Conventions_y\n",
      "Content_y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['essay_id', 'essay_set', 'essay', 'score', 'Prompt Adherence',\n",
       "       'Narrativity', 'Language', 'Word Choice', 'Sentence Fluency',\n",
       "       'Organization', 'Conventions', 'Content'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = main\n",
    "prompt=[]\n",
    "for j in range(6):\n",
    "    i=j+1\n",
    "    print(i)\n",
    "    prompt.append(pd.read_csv('./Prompt-'+str(i)+\".csv\", sep=',', encoding = \"latin\"))\n",
    "    print(prompt[j].describe())\n",
    "#     print(prompt[j].columns)\n",
    "prompt[0][\"Essay ID\"]=prompt[0][\"EssayID\"]\n",
    "for i in [0,1]:\n",
    "    for c in prompt[i].columns:\n",
    "        if c!=\"EssayID\" and c!=\"Essay ID\":\n",
    "            prompt[i][c]=(prompt[i][c]-1)/5\n",
    "for i in [2,3]:\n",
    "    for c in prompt[i].columns:\n",
    "        if c!=\"EssayID\" and c!=\"Essay ID\":\n",
    "            prompt[i][c]=prompt[i][c]/3\n",
    "for i in [4,5]:\n",
    "    for c in prompt[i].columns:\n",
    "        if c!=\"EssayID\" and c!=\"Essay ID\":\n",
    "            prompt[i][c]=prompt[i][c]/4\n",
    "prompt.append(p7)\n",
    "prompt.append(p8)\n",
    "for j in range(8):\n",
    "    i=j+1\n",
    "    print(i)\n",
    "    print(prompt[j].describe())\n",
    "for j in range(8):\n",
    "    temp = pd.merge(new,prompt[j],left_on=\"essay_id\", right_on=\"Essay ID\", how=\"left\")\n",
    "    del temp[\"Essay ID\"]\n",
    "    for col in (c for c in new.columns if c in prompt[j].columns):\n",
    "        print(str(col + '_y'))\n",
    "        temp[col] = temp.apply(lambda x: x[col + '_x'] if x[col + '_x']==x[col + '_x'] else x[col + '_y'], axis=1)\n",
    "#         temp[col] = temp[str(col + '_y')]\n",
    "        del temp[col + '_x'], temp[col + '_y'], \n",
    "    new=temp\n",
    "del temp[\"EssayID\"]\n",
    "new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>score</th>\n",
       "      <th>Prompt Adherence</th>\n",
       "      <th>Narrativity</th>\n",
       "      <th>Language</th>\n",
       "      <th>Word Choice</th>\n",
       "      <th>Sentence Fluency</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Conventions</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12702.000000</td>\n",
       "      <td>12702.000000</td>\n",
       "      <td>12702.000000</td>\n",
       "      <td>7065.000000</td>\n",
       "      <td>7065.000000</td>\n",
       "      <td>8398.000000</td>\n",
       "      <td>4303.000000</td>\n",
       "      <td>4303.000000</td>\n",
       "      <td>5636.000000</td>\n",
       "      <td>5636.000000</td>\n",
       "      <td>12701.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10145.789088</td>\n",
       "      <td>4.129665</td>\n",
       "      <td>0.597187</td>\n",
       "      <td>0.451699</td>\n",
       "      <td>0.470193</td>\n",
       "      <td>0.509040</td>\n",
       "      <td>0.494585</td>\n",
       "      <td>0.515547</td>\n",
       "      <td>0.532032</td>\n",
       "      <td>0.546227</td>\n",
       "      <td>0.485648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6266.002399</td>\n",
       "      <td>2.123601</td>\n",
       "      <td>0.233829</td>\n",
       "      <td>0.286019</td>\n",
       "      <td>0.277591</td>\n",
       "      <td>0.270596</td>\n",
       "      <td>0.207677</td>\n",
       "      <td>0.197891</td>\n",
       "      <td>0.231308</td>\n",
       "      <td>0.231587</td>\n",
       "      <td>0.269731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4371.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9940.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15512.750000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21633.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           essay_id     essay_set         score  Prompt Adherence  \\\n",
       "count  12702.000000  12702.000000  12702.000000       7065.000000   \n",
       "mean   10145.789088      4.129665      0.597187          0.451699   \n",
       "std     6266.002399      2.123601      0.233829          0.286019   \n",
       "min        1.000000      1.000000      0.000000          0.000000   \n",
       "25%     4371.250000      2.000000      0.500000          0.250000   \n",
       "50%     9940.500000      4.000000      0.625000          0.500000   \n",
       "75%    15512.750000      6.000000      0.750000          0.666667   \n",
       "max    21633.000000      8.000000      1.000000          1.000000   \n",
       "\n",
       "       Narrativity     Language  Word Choice  Sentence Fluency  Organization  \\\n",
       "count  7065.000000  8398.000000  4303.000000       4303.000000   5636.000000   \n",
       "mean      0.470193     0.509040     0.494585          0.515547      0.532032   \n",
       "std       0.277591     0.270596     0.207677          0.197891      0.231308   \n",
       "min       0.000000     0.000000     0.000000          0.000000      0.000000   \n",
       "25%       0.333333     0.333333     0.400000          0.400000      0.400000   \n",
       "50%       0.500000     0.500000     0.600000          0.600000      0.600000   \n",
       "75%       0.666667     0.666667     0.600000          0.600000      0.666667   \n",
       "max       1.000000     1.000000     1.000000          1.000000      1.000000   \n",
       "\n",
       "       Conventions       Content  \n",
       "count  5636.000000  12701.000000  \n",
       "mean      0.546227      0.485648  \n",
       "std       0.231587      0.269731  \n",
       "min       0.000000      0.000000  \n",
       "25%       0.400000      0.333333  \n",
       "50%       0.600000      0.500000  \n",
       "75%       0.666667      0.666667  \n",
       "max       1.000000      1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['essay_id', 'essay_set', 'essay', 'score', 'Prompt Adherence',\n",
       "       'Narrativity', 'Language', 'Word Choice', 'Sentence Fluency',\n",
       "       'Organization', 'Conventions', 'Content'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = new[new[\"Content\"]==new[\"Content\"]]\n",
    "new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = new\n",
    "del temp[\"essay_set\"], temp[\"essay\"]\n",
    "temp.to_csv(\"./essay_scores.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['essay_id', 'score', 'Prompt Adherence', 'Narrativity', 'Language',\n",
       "       'Word Choice', 'Sentence Fluency', 'Organization', 'Conventions',\n",
       "       'Content'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
